{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6b3b73b6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"NON-PARAMETRIC INDIVIDUAL CLAIM RESERVING IN INSURANCE\"\n",
    "subtitle: \"Notebook 2 of 3: Building the reserving database\"\n",
    "output:\n",
    "  rmdformats::readthedown:    \n",
    "    number_sections: true  \n",
    "    code_download: true\n",
    "    css: baudry.css\n",
    "    code_folding: show\n",
    "\n",
    "date: \"November 2020\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39171146",
   "metadata": {},
   "source": [
    "# R: Baudry ML Reserving Pt 2\n",
    "\n",
    "*This article was originally created by Nigel Carpenter and published in the [General Insurance Machine Learning for Reserving Working Party (“MLR-WP”) blog](https://institute-and-faculty-of-actuaries.github.io/mlr-blog/). The MLR-WP is an international research group on machine learning techniques to reserving, with over 50 actuaries from around the globe. The goal of the group is to bring machine learning techniques into widespread adoption ‘on the ground’ by identifying what the barriers are, communicating any benefits, and helping develop the research techniques in pragmatic ways. Whilst some articles have been brought into this cookbook, consider exploring the [blog](https://institute-and-faculty-of-actuaries.github.io/mlr-blog/) further for additional content including detailed walkthroughs of more advanced models.*\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This is the second notebook of a series of three that outlines and elaborates upon code used to replicate the central scenario in the paper of Maximilien Baudry \"NON-PARAMETRIC INDIVIDUAL\n",
    "CLAIM RESERVING IN INSURANCE\" ([Presentation](https://www.institutdesactuaires.com/global/gene/link.php?doc_id=11747&fg=1) [Paper](http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/0/6b3d579479584e35c12581eb00468777/$FILE/Reserving-article.pdf))\n",
    "\n",
    "In this notebook we step through the process to create the underlying data structures that will be used in the machine learning reserving process, as set out in sections 2 and 3 of Baudry's paper. \n",
    "\n",
    "The reserving data structures built in this notebook are from a simulated phone insurance dataset. The creation of that simulated dataset has been set out in detail in the first R Notebook of this series. The third Notebook outlines the process for creating reserves using machine learning.\n",
    "\n",
    "# A few words before we start\n",
    "\n",
    "Baudry assumes that a policy follows a [Position Dependent Marked Poisson Process](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7DA57FED4B4CFE953E7DA31B29844967/S0515036100003317a.pdf/claims_reserving_in_continuous_time_a_nonparametric_bayesian_approach.pdf) for which he uses the following graphical representation. \n",
    "\n",
    "![Graphical representation of the PDMPP.](../_static/bauldry/image_1.PNG)\n",
    "Baudry explains the notation and database build in sections 2 and 3 of his paper. It is worth taking the time to familiarise yourself with this way of presenting reserving data as it is a different perspective on the traditional claim triangle. \n",
    "\n",
    "When I first tried to code this paper I had to re-read the approach to building the reserving database many times. Even then the overall process of getting the code to work took weeks and many iterations before it came together for me. So from personal experience I'd say it may take time to understand and follow the details of the approach.  Hopefully this series of notebooks will help speed up that process of familiarisation and having made the investment of time exhibits such as the one below will become intuitive.\n",
    "\n",
    "![Graphical representation of IBNR and RBNS claims.](../_static/bauldry/image_2.PNG)\n",
    "\n",
    "The data requirements for this approach to reserving are more akin to those used in Pricing. Policy underwriting features are directly used in the reserving process requiring policy and claim records to be joined at the policy exposure period level of granularity. In fact I'd say the data requirements are equivalent to a pricing dataset with two added levels of complexity. \n",
    "\n",
    "The first additional complexity is that the history of claim transactions are not aggregated over dimensions of time as they would be in Pricing. The second level of complexity is that by keeping those time dimensions we can include additional data sources in the analysis that would not normally be relevant to Pricing annual policies.  \n",
    "\n",
    "So, for example, explicit use of:  \n",
    "\n",
    "* weather information can be included by joining on the claim occurrence time dimension which, you could imagine, would improve IBNR forecasting;  \n",
    "*  claim settlement features such as claim handler hours worked or claims system downtime can be included by joining on claim processing date. This, you could imagine, would help explain internal variation in claim payment patterns.  \n",
    "\n",
    "The table below summarises the reserve models Baudry builds and the classes of explanatory data features each model uses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a5a7a",
   "metadata": {},
   "source": [
    "|Feature|Description|RBNS|IBNR Frequency|IBNR Severity|\n",
    "|:--|:---------|:-:|:-:|:-:|\n",
    "|$T_{0,p}$| Underwriting features and policy underwriting date|Y|Y|Y|\n",
    "|$t_i - T_{0,p}$| Policy exposure from underwriting date $T_0$ to valuation date $t_i$| Y |Y|Y|\n",
    "|$F_{t_{i,p}}$| Policy risk features at valuation date $t_i$|Y|Y|Y|\n",
    "|$E_{T_{0,p}}$| External information at policy underwriting date $T_0$ |Y|Y|Y|\n",
    "|$E_{T_{1,p}}$| External information at claim occurrence $T_1$|Y|N|N|\n",
    "|$E_{T_{2,p}}$| External information at claim reporting date $T_2$|Y|N|N|\n",
    "|$I_{t_{i,p}}$| Internal claim related information up to valuation date $t_i$|Y|N|N|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb01cc",
   "metadata": {},
   "source": [
    "Baudry shows how this extra data can benefit the reserving process and recognises that it is the adoption of machine learning techniques that enable us to work with larger and more granular volumes of data than we are able to with  traditional chain ladder reserving techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04a05cd",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n",
      "    yday, year\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘cowplot’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    stamp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "\n",
    "library(knitr)\n",
    "library(rmdformats)\n",
    "library(data.table)\n",
    "library(magrittr)\n",
    "library(lubridate)\n",
    "library(ggplot2)\n",
    "library(cowplot)\n",
    "library(repr)\n",
    "library(kableExtra)\n",
    "library(IRdisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a299d47",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "simulate_central_scenario <- function(seed = 1234){\n",
    "  \n",
    "  #seed = 1234  \n",
    "  set.seed(seed)\n",
    "  \n",
    "  # Policy data\n",
    "  #~~~~~~~~~~~~~~~~~\n",
    "  \n",
    "  # polices sold between start 2016 to end 2017\n",
    "  dt_policydates <- data.table(date_UW = seq(as.Date(\"2016/1/1\"), as.Date(\"2017/12/31\"), \"day\"))\n",
    "  \n",
    "  # number of policies per day follows Poisson process with mean 700 (approx 255,500 pols per annum)\n",
    "  dt_policydates[, ':='(policycount = rpois(.N,700),\n",
    "                        date_lapse = date_UW %m+% years(1),\n",
    "                        expodays = as.integer(date_UW %m+% years(1) - date_UW),\n",
    "                        pol_prefix = year(date_UW)*10000 + month(date_UW)*100 + mday(date_UW))]\n",
    "  \n",
    "  \n",
    "  # Add columns defining Policy Covers   \n",
    "  dt_policydates[, Cover_B := round(policycount * 0.25)]\n",
    "  dt_policydates[, Cover_BO := round(policycount * 0.45)]\n",
    "  dt_policydates[, Cover_BOT := policycount - Cover_B - Cover_BO]\n",
    "  \n",
    "  \n",
    "  # repeat rows for each policy by UW-Date\n",
    "  dt_policy <- dt_policydates[rep(1:.N, policycount),c(\"date_UW\", \"pol_prefix\"), with = FALSE][,pol_seq:=1:.N, by=pol_prefix]\n",
    "  \n",
    "  # Create a unique policy number \n",
    "  dt_policy[, pol_number := as.character(pol_prefix * 10000 + pol_seq)]\n",
    "  \n",
    "  # set join keys\n",
    "  setkey(dt_policy,'date_UW')\n",
    "  setkey(dt_policydates,'date_UW')  \n",
    "  \n",
    "  # remove pol_prefix before join\n",
    "  dt_policydates[, pol_prefix := NULL]  \n",
    "  \n",
    "  # join cover from summary file (dt_policydates)\n",
    "  dt_policy <- dt_policy[dt_policydates]  \n",
    "  \n",
    "  # now create Cover field for each policy row\n",
    "  dt_policy[,Cover := 'BO']\n",
    "  dt_policy[pol_seq <= policycount- Cover_BO,Cover := 'BOT']\n",
    "  dt_policy[pol_seq <= Cover_B,Cover := 'B']  \n",
    "  \n",
    "  # remove interim calculation fields\n",
    "  dt_policy[, ':='(pol_prefix = NULL,\n",
    "                   policycount = NULL,\n",
    "                   pol_seq = NULL,\n",
    "                   Cover_B = NULL,\n",
    "                   Cover_BOT = NULL,\n",
    "                   Cover_BO = NULL)]\n",
    "  \n",
    "  # Add remaining policy details\n",
    "  dt_policy[, Brand := rep(rep(c(1,2,3,4), c(9,6,3,2)), length.out = .N)]\n",
    "  dt_policy[, Base_Price := rep(rep(c(600,550,300,150), c(9,6,3,2)), length.out = .N)]\n",
    "  \n",
    "  # models types and model cost multipliers\n",
    "  for (eachBrand in unique(dt_policy$Brand)) {\n",
    "    dt_policy[Brand == eachBrand, Model := rep(rep(c(3,2,1,0), c(10, 7, 2, 1)), length.out = .N)]\n",
    "    dt_policy[Brand == eachBrand, Model_mult := rep(rep(c(1.15^3, 1.15^2, 1.15^1, 1.15^0), c(10, 7, 2, 1)), length.out = .N)]\n",
    "  }\n",
    "  \n",
    "  dt_policy[, Price := ceiling (Base_Price * Model_mult)]\n",
    "  \n",
    "  \n",
    "  # colums to keep\n",
    "  cols_policy <- c(\"pol_number\",\n",
    "                   \"date_UW\",\n",
    "                   \"date_lapse\",\n",
    "                   \"Cover\",\n",
    "                   \"Brand\",\n",
    "                   \"Model\",\n",
    "                   \"Price\")\n",
    "  \n",
    "  dt_policy <- dt_policy[, cols_policy, with = FALSE]\n",
    "  \n",
    "  # check output\n",
    "  #head(dt_policy)\n",
    "  \n",
    "  #save(dt_policy, file = \"./dt_policy.rda\")\n",
    "  \n",
    "  \n",
    "  # Claims data\n",
    "  #~~~~~~~~~~~~~~~~~\n",
    "  \n",
    " # All policies have breakage cover\n",
    "  # claims uniformly sampled from policies\n",
    "  claim <- sample(nrow(dt_policy), size = floor(nrow(dt_policy) * 0.15))\n",
    "  \n",
    "  # Claim serverity multiplier sampled from beta distn\n",
    "  dt_claim <- data.table(pol_number = dt_policy[claim, pol_number],\n",
    "                         claim_type = 'B',\n",
    "                         claim_count = 1,\n",
    "                         claim_sev = rbeta(length(claim), 2,5))\n",
    "  \n",
    "  # identify all policies with Oxidation cover\n",
    "  cov <- which(dt_policy$Cover != 'B')\n",
    "  \n",
    "  # sample claims from policies with cover\n",
    "  claim <- sample(cov, size = floor(length(cov) * 0.05))\n",
    "  \n",
    "  # add claims to table \n",
    "  dt_claim <- rbind(dt_claim,\n",
    "                    data.table(pol_number = dt_policy[claim, pol_number],\n",
    "                               claim_type = 'O',\n",
    "                               claim_count = 1,\n",
    "                               claim_sev = rbeta(length(claim), 5,3)))\n",
    "  \n",
    "  \n",
    "  # identify all policies with Theft cover\n",
    "  # for Theft claim frequency varies by Brand\n",
    "  # So need to consider each in turn...\n",
    "  \n",
    "  for(myModel in 0:3) {\n",
    "    \n",
    "    cov <- which(dt_policy$Cover == 'BOT' & dt_policy$Model == myModel)\n",
    "    claim <- sample(cov, size = floor(length(cov) * 0.05*(1 + myModel)))\n",
    "    \n",
    "    dt_claim <- rbind(dt_claim,\n",
    "                      data.table(pol_number = dt_policy[claim, pol_number],\n",
    "                                 claim_type = 'T',\n",
    "                                 claim_count = 1,\n",
    "                                 claim_sev = rbeta(length(claim), 5,.5)))\n",
    "  }\n",
    "  \n",
    "  # set join keys\n",
    "  setkey(dt_policy, pol_number)\n",
    "  setkey(dt_claim, pol_number)\n",
    "  \n",
    "  #join Brand and Price from policy to claim\n",
    "  dt_claim[dt_policy,\n",
    "           on = 'pol_number',\n",
    "           ':='(date_UW = i.date_UW,\n",
    "                Price = i.Price,\n",
    "                Brand = i.Brand)]\n",
    "  \n",
    "  # use lubridate %m+% date addition operator \n",
    "  dt_claim[, date_lapse := date_UW %m+% years(1)]\n",
    "  dt_claim[, expodays := as.integer(date_lapse - date_UW)]\n",
    "  dt_claim[, occ_delay_days := floor(expodays * runif(.N, 0,1))]\n",
    "  \n",
    "  dt_claim[ ,delay_report := floor(365 * rbeta(.N, .4, 10))]  \n",
    "  dt_claim[ ,delay_pay := floor(10 + 40* rbeta(.N, 7,7))]  \n",
    "  \n",
    "  dt_claim[, date_occur := date_UW %m+% days(occ_delay_days)]\n",
    "  dt_claim[, date_report := date_occur %m+% days(delay_report)]\n",
    "  dt_claim[, date_pay := date_report %m+% days(delay_pay)]\n",
    "  \n",
    "  dt_claim[, claim_cost := round(Price * claim_sev)]\n",
    "  \n",
    "  dt_claim[, clm_prefix := year(date_report)*10000 + month(date_report)*100 + mday(date_report)]\n",
    "  \n",
    "  dt_claim[, clm_seq := seq_len(.N), by = clm_prefix]\n",
    "  dt_claim[, clm_number := as.character(clm_prefix * 10000 + clm_seq)]\n",
    "  \n",
    "  # keep only first claim against policy (competing hazards)\n",
    "  setkeyv(dt_claim, c(\"pol_number\", \"clm_prefix\"))\n",
    "  dt_claim[, polclm_seq := seq_len(.N), by = .(pol_number)]\n",
    "  dt_claim <- dt_claim[polclm_seq == 1,]\n",
    "  \n",
    "\n",
    "  # colums to keep\n",
    "  cols_claim <- c(\"clm_number\",\n",
    "                  \"pol_number\",\n",
    "                  \"claim_type\",\n",
    "                  \"claim_count\",\n",
    "                  \"claim_sev\",\n",
    "                  \"date_occur\",\n",
    "                  \"date_report\",\n",
    "                  \"date_pay\",\n",
    "                  \"claim_cost\")\n",
    "  \n",
    "  dt_claim <- dt_claim[, cols_claim, with = FALSE]\n",
    "  \n",
    "  output <- list()\n",
    "  output$dt_policy <- dt_policy\n",
    "  output$dt_claim <- dt_claim\n",
    "  \n",
    "  return(output)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12507c4",
   "metadata": {},
   "source": [
    "# Simulate policy and claim data\n",
    "\n",
    "We start with the simulated phone insurance policy and claim dataset. I am calling the function from Notebook 1 of this series to create the dataset. Using a fixed seed will ensure you get a reproducible simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea2670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PhoneData <- simulate_central_scenario(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55ed81",
   "metadata": {},
   "source": [
    "We can now inspect the returned Policy dataset and similarly inspect the returned Claim dataset. \n",
    "\n",
    "Both have been created to be somewhat similar to standard policy and claim datasets that insurers would extract from their policy and claim administration systems.\n",
    "\n",
    "## Policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8165d752",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:100%; \"><table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> pol_number </th>\n",
       "   <th style=\"text-align:left;\"> date_UW </th>\n",
       "   <th style=\"text-align:left;\"> date_lapse </th>\n",
       "   <th style=\"text-align:left;\"> Cover </th>\n",
       "   <th style=\"text-align:right;\"> Brand </th>\n",
       "   <th style=\"text-align:right;\"> Model </th>\n",
       "   <th style=\"text-align:right;\"> Price </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010001 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010002 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010003 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010004 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010005 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201601010006 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-01 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 913 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_policy <- dt_PhoneData$dt_policy\n",
    "\n",
    "kable(head(dt_policy), \"html\") %>% \n",
    "  kable_styling(\"striped\") %>% \n",
    "  scroll_box(width = \"100%\") %>%\n",
    "  as.character() %>%\n",
    "  display_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c47a4",
   "metadata": {},
   "source": [
    "## Claim \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a82f70",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:100%; \"><table class=\"table table-striped table-hover table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> clm_number </th>\n",
       "   <th style=\"text-align:left;\"> pol_number </th>\n",
       "   <th style=\"text-align:left;\"> claim_type </th>\n",
       "   <th style=\"text-align:right;\"> claim_count </th>\n",
       "   <th style=\"text-align:right;\"> claim_sev </th>\n",
       "   <th style=\"text-align:left;\"> date_occur </th>\n",
       "   <th style=\"text-align:left;\"> date_report </th>\n",
       "   <th style=\"text-align:left;\"> date_pay </th>\n",
       "   <th style=\"text-align:right;\"> claim_cost </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201606080001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010001 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.3337923 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-06-08 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-06-08 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-07-21 </td>\n",
       "   <td style=\"text-align:right;\"> 305 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201609150001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010014 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.3692034 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-09-15 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-09-15 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-10-17 </td>\n",
       "   <td style=\"text-align:right;\"> 309 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201609090001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010025 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.4496012 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-09-09 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-09-09 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-10-07 </td>\n",
       "   <td style=\"text-align:right;\"> 357 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201602190001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010027 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.4019731 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-01-25 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-02-19 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-03-21 </td>\n",
       "   <td style=\"text-align:right;\"> 319 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201605140001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010043 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.2146653 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-05-14 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-05-14 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-06-15 </td>\n",
       "   <td style=\"text-align:right;\"> 196 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 201612110001 </td>\n",
       "   <td style=\"text-align:left;\"> 201601010045 </td>\n",
       "   <td style=\"text-align:left;\"> B </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.2783313 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-12-11 </td>\n",
       "   <td style=\"text-align:left;\"> 2016-12-11 </td>\n",
       "   <td style=\"text-align:left;\"> 2017-01-06 </td>\n",
       "   <td style=\"text-align:right;\"> 254 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dt_claim <- dt_PhoneData$dt_claim\n",
    "\n",
    "kable(head(dt_claim), \"html\") %>% \n",
    "  kable_styling(c(\"striped\", \"hover\", \"condensed\")) %>% \n",
    "  scroll_box(width = \"100%\") %>%\n",
    "  as.character() %>%\n",
    "  display_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0f495",
   "metadata": {},
   "source": [
    "# Join policy and claim data\n",
    "\n",
    "We wish to join claims to the appropriate policy exposure period. This will be a familiar process to pricing actuaries but may not be familiar to reserving actuaries as it is not a requirement in traditional chain ladder reserving. \n",
    "\n",
    "For speed and convenience we will use the `foverlaps` R function, which needs the tables being joined to have common keys for policy number and time periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849c5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setnames(dt_policy, c('date_UW', 'date_lapse'), c('date_pol_start', 'date_pol_end'))\n",
    "  \n",
    "# set policy start and end dates in foverlap friendly format\n",
    "dt_policy[, date_pol_start:= floor_date(date_pol_start, unit= \"second\")]\n",
    "dt_policy[, date_pol_end:= floor_date(date_pol_end, unit= \"second\") - 1]\n",
    "  \n",
    "# create a dummy end claim occurrence date for foverlap\n",
    "dt_claim[, date_occur:= floor_date(date_occur, unit= \"second\")]\n",
    "dt_claim[, date_occur_end:= date_occur]\n",
    "dt_claim[, date_report:= floor_date(date_report, unit= \"second\")]\n",
    "dt_claim[, date_pay:= floor_date(date_pay, unit= \"second\")]\n",
    "  \n",
    "# set keys for claim join (by policy and dates)\n",
    "setkey(dt_claim, pol_number, date_occur, date_occur_end)\n",
    "setkey(dt_policy, pol_number, date_pol_start, date_pol_end)\n",
    "  \n",
    "# use foverlaps to attach claim to right occurrence period and policy\n",
    "dt_polclaim <- foverlaps(dt_policy, dt_claim, type=\"any\") ## return overlap indices\n",
    "dt_polclaim[, date_occur_end := NULL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89c5a4",
   "metadata": {},
   "source": [
    "The first few rows of the resulting table are shown below where we can see the first policy has an attached claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "decc0d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 61</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pol_number</th><th scope=col>clm_number</th><th scope=col>claim_type</th><th scope=col>claim_count</th><th scope=col>claim_sev</th><th scope=col>date_occur</th><th scope=col>date_report</th><th scope=col>date_pay</th><th scope=col>claim_cost</th><th scope=col>date_pol_start</th><th scope=col>⋯</th><th scope=col>P_t_20180917</th><th scope=col>P_t_20181017</th><th scope=col>P_t_20181116</th><th scope=col>P_t_20181216</th><th scope=col>P_t_20190115</th><th scope=col>P_t_20190214</th><th scope=col>P_t_20190316</th><th scope=col>P_t_20190415</th><th scope=col>P_t_20190515</th><th scope=col>P_t_20190614</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201601010001</td><td>201606080001</td><td>B </td><td>1</td><td>0.3337923</td><td>2016-06-08 00:00:00</td><td>2016-06-08 00:00:00</td><td>2016-07-21 00:00:00</td><td>305</td><td>2016-01-01</td><td>⋯</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td></tr>\n",
       "\t<tr><td>201601010002</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010003</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010004</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010005</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010006</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 61\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " pol\\_number & clm\\_number & claim\\_type & claim\\_count & claim\\_sev & date\\_occur & date\\_report & date\\_pay & claim\\_cost & date\\_pol\\_start & ⋯ & P\\_t\\_20180917 & P\\_t\\_20181017 & P\\_t\\_20181116 & P\\_t\\_20181216 & P\\_t\\_20190115 & P\\_t\\_20190214 & P\\_t\\_20190316 & P\\_t\\_20190415 & P\\_t\\_20190515 & P\\_t\\_20190614\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dttm> & <dttm> & <dttm> & <dbl> & <dttm> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 201601010001 & 201606080001 & B  & 1 & 0.3337923 & 2016-06-08 00:00:00 & 2016-06-08 00:00:00 & 2016-07-21 00:00:00 & 305 & 2016-01-01 & ⋯ & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305\\\\\n",
       "\t 201601010002 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010003 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010004 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010005 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010006 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 61\n",
       "\n",
       "| pol_number &lt;chr&gt; | clm_number &lt;chr&gt; | claim_type &lt;chr&gt; | claim_count &lt;dbl&gt; | claim_sev &lt;dbl&gt; | date_occur &lt;dttm&gt; | date_report &lt;dttm&gt; | date_pay &lt;dttm&gt; | claim_cost &lt;dbl&gt; | date_pol_start &lt;dttm&gt; | ⋯ ⋯ | P_t_20180917 &lt;dbl&gt; | P_t_20181017 &lt;dbl&gt; | P_t_20181116 &lt;dbl&gt; | P_t_20181216 &lt;dbl&gt; | P_t_20190115 &lt;dbl&gt; | P_t_20190214 &lt;dbl&gt; | P_t_20190316 &lt;dbl&gt; | P_t_20190415 &lt;dbl&gt; | P_t_20190515 &lt;dbl&gt; | P_t_20190614 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 201601010001 | 201606080001 | B  | 1 | 0.3337923 | 2016-06-08 00:00:00 | 2016-06-08 00:00:00 | 2016-07-21 00:00:00 | 305 | 2016-01-01 | ⋯ | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 |\n",
       "| 201601010002 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010003 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010004 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010005 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010006 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "\n"
      ],
      "text/plain": [
       "  pol_number   clm_number   claim_type claim_count claim_sev\n",
       "1 201601010001 201606080001 B          1           0.3337923\n",
       "2 201601010002 NA           NA         0           0.0000000\n",
       "3 201601010003 NA           NA         0           0.0000000\n",
       "4 201601010004 NA           NA         0           0.0000000\n",
       "5 201601010005 NA           NA         0           0.0000000\n",
       "6 201601010006 NA           NA         0           0.0000000\n",
       "  date_occur          date_report         date_pay            claim_cost\n",
       "1 2016-06-08 00:00:00 2016-06-08 00:00:00 2016-07-21 00:00:00 305       \n",
       "2 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "3 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "4 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "5 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "6 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "  date_pol_start ⋯ P_t_20180917 P_t_20181017 P_t_20181116 P_t_20181216\n",
       "1 2016-01-01     ⋯ 305          305          305          305         \n",
       "2 2016-01-01     ⋯   0            0            0            0         \n",
       "3 2016-01-01     ⋯   0            0            0            0         \n",
       "4 2016-01-01     ⋯   0            0            0            0         \n",
       "5 2016-01-01     ⋯   0            0            0            0         \n",
       "6 2016-01-01     ⋯   0            0            0            0         \n",
       "  P_t_20190115 P_t_20190214 P_t_20190316 P_t_20190415 P_t_20190515 P_t_20190614\n",
       "1 305          305          305          305          305          305         \n",
       "2   0            0            0            0            0            0         \n",
       "3   0            0            0            0            0            0         \n",
       "4   0            0            0            0            0            0         \n",
       "5   0            0            0            0            0            0         \n",
       "6   0            0            0            0            0            0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dt_polclaim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdcebea",
   "metadata": {},
   "source": [
    "## Check for multi-claim policies\n",
    "\n",
    "In a real world situation it is possible for policies to have multiple claims in an insurance period. In such circumstances care needs to be taken in matching policy exposure periods and claims, typically this is done by splitting a policy into sequences that stop at the date of each claim. \n",
    "\n",
    "Our simulated data does not have this complication, as this check shows, the max number or sequences is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78cece45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     1 \n",
       "512246 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "setkey(dt_polclaim, pol_number, date_pol_start)\n",
    "  \n",
    "# create 2 new cols that count how many claims against each policy\n",
    "dt_polclaim[,\n",
    "            ':='(pol_seq = seq_len(.N),\n",
    "                 pol_seq_max = .N),\n",
    "            by = c('pol_number', 'date_pol_start') ]\n",
    "  \n",
    "table(dt_polclaim[, pol_seq_max])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d6910",
   "metadata": {},
   "source": [
    "Not all policies have claims, resulting in NA fields in the joined dataset. To facilitate future processing we need to deal with NA fields in the joined policy and claims dataset. Missing dates are set to a long dated future point. Where there are no claims, we set claim counts and costs to zero, resulting in the following table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f152cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set NA dates to 31/12/2999\n",
    "lst_datefields <- grep(names(dt_polclaim),pattern = \"date\", value = TRUE)\n",
    "  \n",
    "for (datefield in lst_datefields)\n",
    "  set(dt_polclaim,which(is.na(dt_polclaim[[datefield]])),datefield,as_datetime(\"2199-12-31 23:59:59 UTC\"))\n",
    " \n",
    "#set other NAs to zero (claim counts and costs)\n",
    "for (field in c(\"claim_count\", \"claim_sev\", \"claim_cost\"))\n",
    "  set(dt_polclaim,which(is.na(dt_polclaim[[field]])),field,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ae1dc6",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 1610477</td><td> 86.1</td><td> 3663570</td><td>195.7</td><td>   NA</td><td> 3663570</td><td>195.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>16460718</td><td>125.6</td><td>31725974</td><td>242.1</td><td>16384</td><td>31555645</td><td>240.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  1610477 &  86.1 &  3663570 & 195.7 &    NA &  3663570 & 195.7\\\\\n",
       "\tVcells & 16460718 & 125.6 & 31725974 & 242.1 & 16384 & 31555645 & 240.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |  1610477 |  86.1 |  3663570 | 195.7 |    NA |  3663570 | 195.7 |\n",
       "| Vcells | 16460718 | 125.6 | 31725974 | 242.1 | 16384 | 31555645 | 240.8 |\n",
       "\n"
      ],
      "text/plain": [
       "       used     (Mb)  gc trigger (Mb)  limit (Mb) max used (Mb) \n",
       "Ncells  1610477  86.1  3663570   195.7    NA       3663570 195.7\n",
       "Vcells 16460718 125.6 31725974   242.1 16384      31555645 240.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Clean up ----\n",
    "dt_polclaim[, ExpoDays:= ceiling((as.numeric(date_pol_end) - as.numeric(date_pol_start))/(24*60*60*365))]\n",
    "dt_polclaim <- dt_polclaim[ExpoDays > 0]\n",
    "  \n",
    "rm(dt_claim)\n",
    "rm(dt_policy)\n",
    "  \n",
    "gc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac4588b2",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 61</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pol_number</th><th scope=col>clm_number</th><th scope=col>claim_type</th><th scope=col>claim_count</th><th scope=col>claim_sev</th><th scope=col>date_occur</th><th scope=col>date_report</th><th scope=col>date_pay</th><th scope=col>claim_cost</th><th scope=col>date_pol_start</th><th scope=col>⋯</th><th scope=col>P_t_20180917</th><th scope=col>P_t_20181017</th><th scope=col>P_t_20181116</th><th scope=col>P_t_20181216</th><th scope=col>P_t_20190115</th><th scope=col>P_t_20190214</th><th scope=col>P_t_20190316</th><th scope=col>P_t_20190415</th><th scope=col>P_t_20190515</th><th scope=col>P_t_20190614</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201601010001</td><td>201606080001</td><td>B </td><td>1</td><td>0.3337923</td><td>2016-06-08 00:00:00</td><td>2016-06-08 00:00:00</td><td>2016-07-21 00:00:00</td><td>305</td><td>2016-01-01</td><td>⋯</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td></tr>\n",
       "\t<tr><td>201601010002</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010003</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010004</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010005</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010006</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 61\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " pol\\_number & clm\\_number & claim\\_type & claim\\_count & claim\\_sev & date\\_occur & date\\_report & date\\_pay & claim\\_cost & date\\_pol\\_start & ⋯ & P\\_t\\_20180917 & P\\_t\\_20181017 & P\\_t\\_20181116 & P\\_t\\_20181216 & P\\_t\\_20190115 & P\\_t\\_20190214 & P\\_t\\_20190316 & P\\_t\\_20190415 & P\\_t\\_20190515 & P\\_t\\_20190614\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dttm> & <dttm> & <dttm> & <dbl> & <dttm> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 201601010001 & 201606080001 & B  & 1 & 0.3337923 & 2016-06-08 00:00:00 & 2016-06-08 00:00:00 & 2016-07-21 00:00:00 & 305 & 2016-01-01 & ⋯ & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305\\\\\n",
       "\t 201601010002 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010003 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010004 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010005 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010006 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 61\n",
       "\n",
       "| pol_number &lt;chr&gt; | clm_number &lt;chr&gt; | claim_type &lt;chr&gt; | claim_count &lt;dbl&gt; | claim_sev &lt;dbl&gt; | date_occur &lt;dttm&gt; | date_report &lt;dttm&gt; | date_pay &lt;dttm&gt; | claim_cost &lt;dbl&gt; | date_pol_start &lt;dttm&gt; | ⋯ ⋯ | P_t_20180917 &lt;dbl&gt; | P_t_20181017 &lt;dbl&gt; | P_t_20181116 &lt;dbl&gt; | P_t_20181216 &lt;dbl&gt; | P_t_20190115 &lt;dbl&gt; | P_t_20190214 &lt;dbl&gt; | P_t_20190316 &lt;dbl&gt; | P_t_20190415 &lt;dbl&gt; | P_t_20190515 &lt;dbl&gt; | P_t_20190614 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 201601010001 | 201606080001 | B  | 1 | 0.3337923 | 2016-06-08 00:00:00 | 2016-06-08 00:00:00 | 2016-07-21 00:00:00 | 305 | 2016-01-01 | ⋯ | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 |\n",
       "| 201601010002 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010003 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010004 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010005 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010006 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "\n"
      ],
      "text/plain": [
       "  pol_number   clm_number   claim_type claim_count claim_sev\n",
       "1 201601010001 201606080001 B          1           0.3337923\n",
       "2 201601010002 NA           NA         0           0.0000000\n",
       "3 201601010003 NA           NA         0           0.0000000\n",
       "4 201601010004 NA           NA         0           0.0000000\n",
       "5 201601010005 NA           NA         0           0.0000000\n",
       "6 201601010006 NA           NA         0           0.0000000\n",
       "  date_occur          date_report         date_pay            claim_cost\n",
       "1 2016-06-08 00:00:00 2016-06-08 00:00:00 2016-07-21 00:00:00 305       \n",
       "2 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "3 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "4 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "5 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "6 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "  date_pol_start ⋯ P_t_20180917 P_t_20181017 P_t_20181116 P_t_20181216\n",
       "1 2016-01-01     ⋯ 305          305          305          305         \n",
       "2 2016-01-01     ⋯   0            0            0            0         \n",
       "3 2016-01-01     ⋯   0            0            0            0         \n",
       "4 2016-01-01     ⋯   0            0            0            0         \n",
       "5 2016-01-01     ⋯   0            0            0            0         \n",
       "6 2016-01-01     ⋯   0            0            0            0         \n",
       "  P_t_20190115 P_t_20190214 P_t_20190316 P_t_20190415 P_t_20190515 P_t_20190614\n",
       "1 305          305          305          305          305          305         \n",
       "2   0            0            0            0            0            0         \n",
       "3   0            0            0            0            0            0         \n",
       "4   0            0            0            0            0            0         \n",
       "5   0            0            0            0            0            0         \n",
       "6   0            0            0            0            0            0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dt_polclaim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8404fba",
   "metadata": {},
   "source": [
    "# Timeslicing claim payments\n",
    "\n",
    "Although this paper works with individual policy and claim transactions those transactions are collated into time slices. \n",
    "\n",
    "Baudry selected time slices of 30 days in length starting from 01 Jan 2016 (Section 5 page 13). \n",
    "\n",
    "![Graphical representation of the PDMPP.](../_static/bauldry/image_3.PNG)\n",
    "\n",
    "In the code below, for every individual policy and claim transaction; ie row in `dt_polclaim`, we are creating an extra column for each possible timeslice and recording in the column the cumulative claim cost up to that time slice. \n",
    "\n",
    "Given that in the simple simulated dataset we only have one claim payment for any claim, the code to do this is rather more simple than would otherwise be the case. The code below would need to be amended if there are partial claim payments.  \n",
    "\n",
    "This time sliced dataset becomes the source of our RBNS and IBNER datasets used in subsequent machine learning steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0c4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_Date_slice <- floor_date(seq(as.Date(\"2016/1/1\"), as.Date(\"2019/06/30\"), by = 30), unit= \"second\") \n",
    "\n",
    "# Time slice Policy & claims \n",
    " \n",
    "for (i in 1:length(lst_Date_slice)){\n",
    "  dt_polclaim[date_pay<= lst_Date_slice[i], paste0('P_t_', format(lst_Date_slice[i], \"%Y%m%d\")):= claim_cost]\n",
    "  set(dt_polclaim,which(is.na(dt_polclaim[[paste0('P_t_', format(lst_Date_slice[i], \"%Y%m%d\"))]])),paste0('P_t_', format(lst_Date_slice[i], \"%Y%m%d\")),0)\n",
    "}\n",
    "  \n",
    "# sort data by policynumber\n",
    "setkey(dt_polclaim, pol_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a674f8",
   "metadata": {},
   "source": [
    "Looking at the data can see the output of timeslicing. You'll need to scroll to the right of the table to see the columns labeled **P_t_20160101** through to **P_t_20190614**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a76b900",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 61</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>pol_number</th><th scope=col>clm_number</th><th scope=col>claim_type</th><th scope=col>claim_count</th><th scope=col>claim_sev</th><th scope=col>date_occur</th><th scope=col>date_report</th><th scope=col>date_pay</th><th scope=col>claim_cost</th><th scope=col>date_pol_start</th><th scope=col>⋯</th><th scope=col>P_t_20180917</th><th scope=col>P_t_20181017</th><th scope=col>P_t_20181116</th><th scope=col>P_t_20181216</th><th scope=col>P_t_20190115</th><th scope=col>P_t_20190214</th><th scope=col>P_t_20190316</th><th scope=col>P_t_20190415</th><th scope=col>P_t_20190515</th><th scope=col>P_t_20190614</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201601010001</td><td>201606080001</td><td>B </td><td>1</td><td>0.3337923</td><td>2016-06-08 00:00:00</td><td>2016-06-08 00:00:00</td><td>2016-07-21 00:00:00</td><td>305</td><td>2016-01-01</td><td>⋯</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td><td>305</td></tr>\n",
       "\t<tr><td>201601010002</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010003</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010004</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010005</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><td>201601010006</td><td>NA          </td><td>NA</td><td>0</td><td>0.0000000</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>  0</td><td>2016-01-01</td><td>⋯</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 61\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " pol\\_number & clm\\_number & claim\\_type & claim\\_count & claim\\_sev & date\\_occur & date\\_report & date\\_pay & claim\\_cost & date\\_pol\\_start & ⋯ & P\\_t\\_20180917 & P\\_t\\_20181017 & P\\_t\\_20181116 & P\\_t\\_20181216 & P\\_t\\_20190115 & P\\_t\\_20190214 & P\\_t\\_20190316 & P\\_t\\_20190415 & P\\_t\\_20190515 & P\\_t\\_20190614\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dttm> & <dttm> & <dttm> & <dbl> & <dttm> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 201601010001 & 201606080001 & B  & 1 & 0.3337923 & 2016-06-08 00:00:00 & 2016-06-08 00:00:00 & 2016-07-21 00:00:00 & 305 & 2016-01-01 & ⋯ & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305 & 305\\\\\n",
       "\t 201601010002 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010003 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010004 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010005 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\t 201601010006 & NA           & NA & 0 & 0.0000000 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 &   0 & 2016-01-01 & ⋯ &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0 &   0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 61\n",
       "\n",
       "| pol_number &lt;chr&gt; | clm_number &lt;chr&gt; | claim_type &lt;chr&gt; | claim_count &lt;dbl&gt; | claim_sev &lt;dbl&gt; | date_occur &lt;dttm&gt; | date_report &lt;dttm&gt; | date_pay &lt;dttm&gt; | claim_cost &lt;dbl&gt; | date_pol_start &lt;dttm&gt; | ⋯ ⋯ | P_t_20180917 &lt;dbl&gt; | P_t_20181017 &lt;dbl&gt; | P_t_20181116 &lt;dbl&gt; | P_t_20181216 &lt;dbl&gt; | P_t_20190115 &lt;dbl&gt; | P_t_20190214 &lt;dbl&gt; | P_t_20190316 &lt;dbl&gt; | P_t_20190415 &lt;dbl&gt; | P_t_20190515 &lt;dbl&gt; | P_t_20190614 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 201601010001 | 201606080001 | B  | 1 | 0.3337923 | 2016-06-08 00:00:00 | 2016-06-08 00:00:00 | 2016-07-21 00:00:00 | 305 | 2016-01-01 | ⋯ | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 | 305 |\n",
       "| 201601010002 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010003 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010004 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010005 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "| 201601010006 | NA           | NA | 0 | 0.0000000 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 |   0 | 2016-01-01 | ⋯ |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |\n",
       "\n"
      ],
      "text/plain": [
       "  pol_number   clm_number   claim_type claim_count claim_sev\n",
       "1 201601010001 201606080001 B          1           0.3337923\n",
       "2 201601010002 NA           NA         0           0.0000000\n",
       "3 201601010003 NA           NA         0           0.0000000\n",
       "4 201601010004 NA           NA         0           0.0000000\n",
       "5 201601010005 NA           NA         0           0.0000000\n",
       "6 201601010006 NA           NA         0           0.0000000\n",
       "  date_occur          date_report         date_pay            claim_cost\n",
       "1 2016-06-08 00:00:00 2016-06-08 00:00:00 2016-07-21 00:00:00 305       \n",
       "2 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "3 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "4 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "5 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "6 2199-12-31 23:59:59 2199-12-31 23:59:59 2199-12-31 23:59:59   0       \n",
       "  date_pol_start ⋯ P_t_20180917 P_t_20181017 P_t_20181116 P_t_20181216\n",
       "1 2016-01-01     ⋯ 305          305          305          305         \n",
       "2 2016-01-01     ⋯   0            0            0            0         \n",
       "3 2016-01-01     ⋯   0            0            0            0         \n",
       "4 2016-01-01     ⋯   0            0            0            0         \n",
       "5 2016-01-01     ⋯   0            0            0            0         \n",
       "6 2016-01-01     ⋯   0            0            0            0         \n",
       "  P_t_20190115 P_t_20190214 P_t_20190316 P_t_20190415 P_t_20190515 P_t_20190614\n",
       "1 305          305          305          305          305          305         \n",
       "2   0            0            0            0            0            0         \n",
       "3   0            0            0            0            0            0         \n",
       "4   0            0            0            0            0            0         \n",
       "5   0            0            0            0            0            0         \n",
       "6   0            0            0            0            0            0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dt_polclaim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710b92",
   "metadata": {},
   "source": [
    "# Creating RBNS and IBNER datasets\n",
    "\n",
    "Before we create the RBNS and IBNER datasets we must pick a valuation point from the available timeslices. I'm selecting the 10th point for illustration, which is the 10th 30 day period from 01/01/2016, ie a valuation date of 27/09/2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d319856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ 2.1 Set initial variables ----\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "i <- valuation <- 10\n",
    "t_i <- lst_Date_slice[i] \n",
    "delta <- min(i, length(lst_Date_slice) - i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d32e35",
   "metadata": {},
   "source": [
    "In a traditional approach we would be creating reserving triangles with 10, 30 day duration development periods. \n",
    "\n",
    "As we will see the approach adopted by Baudry, in section 3 of his paper, is somewhat different and is much closer to the sort of datasets that Pricing Actuaries are familiar with. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a503ce4",
   "metadata": {},
   "source": [
    "## Creating RBNS dataset\n",
    "\n",
    "We start with the RBNS dataset.\n",
    "\n",
    "The training data for the for the RBNS reserves will consist of all claims reported prior to the valuation date. This data has been joined to the policy exposure data to enable policy related features to be used as explanatory variables in the RBNS reserve calculation. \n",
    "\n",
    "A training dataset will enable us to build a model of RBNS reserve requirements at historic valuation dates. But what we really require is a view of the RBNS reserve at the valuation date. To calculate this we need to create a test dataset that contains values of the explanatory features at each future claim payment period. \n",
    "\n",
    "By making model prediction for each row of the test dataset we can calculate the RBNS reserve as the sum of predicted future payments. \n",
    "\n",
    "## RBNS dataset functions {.tabset}\n",
    "\n",
    "To create the RBNS train and test datasets we have provided two functions `RBNS_Train_ijk` and `RBNS_Test_ijk` which take as an input the joined policy and claims dataset and return data in a format suitable for applying machine learning.\n",
    "\n",
    "They are actually returning the 'triangle' data for all occurrence periods, **i**, for a specified: \n",
    "\n",
    "* claim development delay, **j**; and\n",
    "* model type **k**\n",
    "\n",
    "For values of **k** equal to 1 claim transactions up to the valuation date are included. When **k** is set to 2 transactions in the calendar period immediately prior to the valuation date are excluded. Although in this example only models with a **k** value of 1 are created, Baudry's framework allows for multiple **k** value models to be built. In doing so multiple models are created, effectively using aged data which would allow an ensemble modeling approach to be used. Such use of multiple **k** values would be similar to a Bornhuetter-Ferguson approach to modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7604607",
   "metadata": {},
   "source": [
    "### RBNS_Train\n",
    "\n",
    "The code for creating the RBNS datasets is rather involved so detailed explanation has been skipped over here.  \n",
    "Interested readers are encouraged to come back to this stage and inspect the code and Baudry’s paper once they have an overview of the wider process.\n",
    "\n",
    "I should call out that the code shared here deals only with the simplified payment process from Baudry's central scenario, ie claims are settled with a single payment. Real world data with partial payments would require material changes to be made to the code we have shared. Such changes are left for interested readers to make.\n",
    "\n",
    "I'll also flag here, and expand in notebook 3, that the \"settled with a single payment assumption\" prevents claim payment information from being used as an explanatory feature in the subsequent machine learning process of notebook 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503304a1",
   "metadata": {
    "echo": true,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "RBNS_Train_ijk <- function(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars) {\n",
    "  \n",
    "  # # debugging\n",
    "  # #~~~~~~~~~~~~~\n",
    "  # dt_policy_claim = dt_polclaim\n",
    "  # date_i = t_i\n",
    "  # j_dev_period = 1\n",
    "  # k = 1\n",
    "  # reserving_dates = lst_Date_slice\n",
    "  # #~~~~~~~~~~~~~\n",
    "  #   \n",
    "  \n",
    "  date_i <- as.Date(date_i)\n",
    "  date_k <- (reserving_dates[which(reserving_dates == date_i) - k + 1])\n",
    "  date_j <- (reserving_dates[which(reserving_dates == date_k) - j_dev_period])\n",
    "  \n",
    "  #i - j - k + 1 (predictor as at date)\n",
    "  date_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - j_dev_period -k + 1]) \n",
    "  \n",
    "  #i - k to calculate target incremental paid\n",
    "  target_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - k]) \n",
    "  \n",
    "  #i -k + 1 to calculate target incremental paid\n",
    "  target_lookup_next <- (reserving_dates[which(reserving_dates == (date_i)) - k + 1]) \n",
    "  \n",
    "  #definition of reported but not settled\n",
    "  dt_policy_claim <- dt_policy_claim[(date_report <= date_lookup) & (date_pay > date_lookup)] \n",
    "  \n",
    "  #simulated data assumes one payment so just need to check date paid in target calc\n",
    "  dt_policy_claim[, ':='(date_lookup = date_lookup,\n",
    "                         delay_train = as.numeric(date_lookup - date_pol_start), #extra feature\n",
    "                         j = j_dev_period,\n",
    "                         k = k,\n",
    "                         target = ifelse(date_pay<=target_lookup,0,ifelse(date_pay<=target_lookup_next,claim_cost,0)))]\n",
    "  \n",
    "  return(dt_policy_claim[, model_vars, with = FALSE])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84517437",
   "metadata": {},
   "source": [
    "### RBNS_Test\n",
    "\n",
    "The code for creating the RBNS datasets is rather involved so detailed explanation has been skipped over here.  \n",
    "Interested readers are encouraged to come back to this stage and inspect the code and Baudry’s paper once they have an overview of the wider process.\n",
    "\n",
    "I should call out that the code shared here deals only with the simplified payment process from Baudry's central scenario, ie claims are settled with a single payment. Real world data with partial payments would require material changes to be made to the code we have shared. Such changes are left for interested readers to make.\n",
    "\n",
    "I'll also flag here, and expand in notebook 3, that the \"settled with a single payment assumption\" prevents claim payment information from being used as an explanatory feature in the subsequent machine learning process of notebook 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91481ec",
   "metadata": {
    "echo": true
   },
   "outputs": [],
   "source": [
    "RBNS_Test_ijk <- function(dt_policy_claim, date_i,j_dev_period, k, reserving_dates, model_vars) {\n",
    "  \n",
    "  # # debugging\n",
    "  # #~~~~~~~~~~~~~\n",
    "  # dt_policy_claim = dt_polclaim\n",
    "  # date_i = t_i\n",
    "  # j_dev_period = 1\n",
    "  # k = 1\n",
    "  # reserving_dates = lst_Date_slice\n",
    "  # #~~~~~~~~~~~~~\n",
    "  #   \n",
    "  date_i <- as.Date(date_i)\n",
    "  \n",
    "  #i - j - k + 1 (predictor as at date)\n",
    "  date_lookup <- (reserving_dates[which(reserving_dates == (date_i))]) \n",
    "  \n",
    "  #i - k to calculate target incremental paid\n",
    "  target_lookup <- (reserving_dates[which(reserving_dates == (date_i)) +j_dev_period - 1]) \n",
    "  \n",
    "  #i -k + 1 to calculate target incremental paid  \n",
    "  target_lookup_next <- (reserving_dates[which(reserving_dates == (date_i)) + j_dev_period]) \n",
    "  \n",
    "  #definition of reported but not settled\n",
    "  # P_te_RBNS rowids of policies needing an RBNS reserve\n",
    "  dt_policy_claim <- dt_policy_claim[date_report <= date_lookup & date_lookup < date_pay] \n",
    "  \n",
    "  #model assumes one payment so just need to check date paid\n",
    "  dt_policy_claim[, ':='(date_lookup = date_lookup,\n",
    "                         delay_train = as.numeric(date_lookup - date_pol_start), #extra feature\n",
    "                         j = j_dev_period,\n",
    "                         k = k,\n",
    "                         target = ifelse(date_pay<=target_lookup,0,ifelse(date_pay<=target_lookup_next,claim_cost,0)))] \n",
    "  \n",
    "return(dt_policy_claim[, model_vars, with = FALSE])\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a44d0",
   "metadata": {},
   "source": [
    "## RBNS function calls\n",
    "\n",
    "The RBNS train and test datasets are created by calling the `RBNS_Train` and `RBNS_Test` functions passing, as parameters to them, the names of the joined policy and claim dataset, valuation dates and model features. \n",
    "\n",
    "The functions  `RBNS_Train` and `RBNS_Test` iterate over valid values of j and k calling the `RBNS_Train_ijk` and `RBNS_Test_ijk` functions to create the complete train and test datasets as illustrated below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08c30c",
   "metadata": {},
   "source": [
    "![train](../_static/bauldry/image_5a.png)\n",
    "\n",
    "![test](../_static/bauldry/image_6a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b623c6d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "RBNS_Train <- function(dt_policy_claim, date_i, i, k, reserving_dates, model_vars) {\n",
    "# Create a combined TRAIN dataset across all k and j combos\n",
    "  for (k in 1:k){\n",
    "    if (k==1) dt_train <- NULL\n",
    "    for (j in 1:(i - k + 1)){\n",
    "      dt_train <- rbind(dt_train, RBNS_Train_ijk(dt_polclaim, date_i, j, k,reserving_dates, model_vars))\n",
    "    }\n",
    "  }  \n",
    "  return(dt_train)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1917606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RBNS_Test <- function(dt_policy_claim, date_i, delta, k, reserving_dates, model_vars) {\n",
    "  \n",
    "  # Create a combined TEST dataset across all k and j combos\n",
    "  for (k in 1:k){\n",
    "    if (k==1) dt_test <- NULL\n",
    "    for (j in 1:(delta - k + 1)){\n",
    "      dt_test <- rbind(dt_test, RBNS_Test_ijk(dt_polclaim, date_i, j, k,reserving_dates, model_vars))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(dt_test)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7e828",
   "metadata": {},
   "source": [
    "The animation below attempts to summarise the overall data preparation and model prediction process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea640064",
   "metadata": {},
   "source": [
    "![Triangles](../_static/bauldry/Triangles.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215afea",
   "metadata": {},
   "source": [
    "So having given a rough outline of the data creation process let's now call the functions to create the RBNS datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "614390c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define modelVars\n",
    "RBNS_model_vars <- c(\"clm_number\",\n",
    "                     \"pol_number\",\n",
    "                     \"j\",\n",
    "                     \"k\",\n",
    "                     \"date_pol_start\",\n",
    "                     \"date_occur\",\n",
    "                     \"date_report\",\n",
    "                     \"date_pay\",\n",
    "                     \"Cover\",\n",
    "                     \"claim_type\",\n",
    "                     \"Brand\",\n",
    "                     \"Model\",\n",
    "                     \"Price\",\n",
    "                     \"target\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a combined TRAIN dataset for k = 1 and all valid j delay values\n",
    "dt_RBNS_train <- RBNS_Train(dt_polclaim, t_i, i, k = 1, lst_Date_slice, RBNS_model_vars)\n",
    "\n",
    "# Create a combined TEST dataset for k = 1 and all valid j delay values\n",
    "dt_RBNS_test <- RBNS_Test(dt_polclaim, t_i, delta, k = 1, lst_Date_slice, RBNS_model_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57c673",
   "metadata": {},
   "source": [
    "The train and test datasets are then joined into a single dataset and a small amount of tidying is done to make them ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33488dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a flag to determine which rows are from the trainset and which from the test set\n",
    "dt_RBNS_train[, flgTrain := 1]\n",
    "dt_RBNS_test[, flgTrain := 0]\n",
    "\n",
    "# combine into a single RBNS dataset   \n",
    "dt_All_RBNS <- rbind(dt_RBNS_train, dt_RBNS_test)\n",
    "#write.csv(dt_All_RBNS,\"dt_All_RBNS.csv\", row.names = F)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65330940",
   "metadata": {
    "language": "undefined",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 1616812</td><td> 86.4</td><td> 3663570</td><td>195.7</td><td>   NA</td><td> 3663570</td><td>195.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>39160591</td><td>298.8</td><td>66216417</td><td>505.2</td><td>16384</td><td>54961732</td><td>419.4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  1616812 &  86.4 &  3663570 & 195.7 &    NA &  3663570 & 195.7\\\\\n",
       "\tVcells & 39160591 & 298.8 & 66216417 & 505.2 & 16384 & 54961732 & 419.4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |  1616812 |  86.4 |  3663570 | 195.7 |    NA |  3663570 | 195.7 |\n",
       "| Vcells | 39160591 | 298.8 | 66216417 | 505.2 | 16384 | 54961732 | 419.4 |\n",
       "\n"
      ],
      "text/plain": [
       "       used     (Mb)  gc trigger (Mb)  limit (Mb) max used (Mb) \n",
       "Ncells  1616812  86.4  3663570   195.7    NA       3663570 195.7\n",
       "Vcells 39160591 298.8 66216417   505.2 16384      54961732 419.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tidy up\n",
    "rm(dt_RBNS_train)\n",
    "rm(dt_RBNS_test)\n",
    "gc()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd766d",
   "metadata": {},
   "source": [
    "The important aspects of the tidying relate to creating useable delay metrics from the numerous dates and converting some character features such as cover and claim type into factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da694a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# order and create some delay fields\n",
    "setkey(dt_All_RBNS, clm_number, k, j)\n",
    "    \n",
    "dt_All_RBNS[, Count := .N , by =clm_number]\n",
    "\n",
    "#create date and delay measure by converting from source seconds since 01/01/1970 to day periods\n",
    "\n",
    "dt_All_RBNS[, ':='(\n",
    "  delay_uw_occ = ifelse(year(date_occur) == 2199,\n",
    "                        -1,\n",
    "                        ceiling((as.numeric(date_occur) - as.numeric(date_pol_start)) / (24 * 60 * 60))\n",
    "                        ),\n",
    "  delay_occ_rep = ifelse(year(date_occur) == 2199,\n",
    "                         -1,\n",
    "                         ceiling((as.numeric(date_report) - as.numeric(date_occur)) / (24 * 60 * 60))\n",
    "                         ),\n",
    "  \n",
    "  delay_uw_val = ceiling((as.numeric(t_i) - as.numeric(date_pol_start)) / (24 * 60 * 60)),\n",
    "  delay_rep_pay = ceiling((as.numeric(date_pay) - as.numeric(date_report)) / (24 * 60 * 60)),\n",
    "  date_uw = ceiling(as.numeric(date_pol_start) / (24 *  60 * 60)),\n",
    "  \n",
    "  Cover = as.factor(Cover),\n",
    "  claim_type = as.factor(claim_type)\n",
    "  )]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cbc47",
   "metadata": {},
   "source": [
    "## Creating IBNR dataset\n",
    "\n",
    "The IBNR dataset creation follows a similar process to RBNS but is a little more complex. Any policy with a live exposure can give rise to an IBNR claim so the training dataset consists of all policy exposure periods prior to the valuation date. \n",
    "\n",
    "From this we train two models:\n",
    "\n",
    "* a frequency model to predict if there will be an IBNR claim; and\n",
    "* a severity model to predict the expected cost of any IBNR claim\n",
    "\n",
    "This is very similar to the traditional pricing approach except that we can add information relating to the claim occurrence date (eg weather information could be useful for Storm losses) and we also predict the incremental run-off of the exposure period.  \n",
    "\n",
    "## IBNR dataset functions {.tabset}\n",
    "\n",
    "### IBNR_Frequency Train\n",
    "The code for creating the IBNR datasets is rather involved so detailed explanation has been skipped over here.  \n",
    "Interested readers are encouraged to come back to this stage and inspect the code and Baudry’s paper once they have an overview of the wider process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda06fc1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IBNR_Freq_Train_ijk <- function(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars, verbose = FALSE) {\n",
    "  \n",
    "  # # debugging\n",
    "  # #~~~~~~~~~~~~~\n",
    "  # dt_policy_claim = dt_polclaim\n",
    "  # date_i = t_i\n",
    "  # j_dev_period = 1\n",
    "  # k = 1\n",
    "  # reserving_dates = lst_Date_slice\n",
    "  # model_vars <- IBNR_model_vars\n",
    "  # #~~~~~~~~~~~~~\n",
    "  \n",
    "  date_i <- as.Date(date_i)\n",
    "  date_k <- (reserving_dates[which(reserving_dates == date_i) - k + 1])\n",
    "  date_j <- (reserving_dates[which(reserving_dates == date_k) - j_dev_period])\n",
    "  date_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - j_dev_period -k + 1]) #i - j - k + 1 (predictor as at date)\n",
    "  target_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - k]) #i - k to calculate target incremental paid\n",
    "  target_lookup_next <- (reserving_dates[which(reserving_dates == (date_i)) - k + 1]) #i -k + 1 to calculate targte incremental paid\n",
    "  \n",
    "  if(verbose) cat(paste(\"Valn date\", date_i, \", j = \", j_dev_period, \", k =\", k, \"\\n\"))\n",
    "  \n",
    "  dt_policy_claim <- dt_policy_claim[date_pol_start < date_lookup  & date_lookup < date_report] #definition of IBNR\n",
    "  \n",
    "  dt_policy_claim[, ':='(date_lookup = date_lookup,\n",
    "                         delay_train = as.numeric(date_lookup - date_pol_start), #extra feature\n",
    "                         j = j_dev_period,\n",
    "                         k = k,\n",
    "                         exposure = round((pmin(as.numeric(as.numeric(date_pol_end)), as.numeric(floor_date(date_i, unit= \"second\")))\n",
    "                                             - as.numeric(date_pol_start))/(24*60*60*365), 3),\n",
    "                         target = ifelse(target_lookup <= date_pay &  date_pay< target_lookup_next & date_occur <= date_lookup ,1,0))]\n",
    "  \n",
    "  dt_policy_claim <- dt_policy_claim [,.(exposure = sum(exposure)), by= c(setdiff(model_vars, 'exposure')) ]\n",
    "  \n",
    "  return(dt_policy_claim[, model_vars, with = FALSE])\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986176e4",
   "metadata": {},
   "source": [
    "### IBNR_Loss Train\n",
    "The code for creating the IBNR datasets is rather involved so detailed explanation has been skipped over here.  \n",
    "Interested readers are encouraged to come back to this stage and inspect the code and Baudry’s paper once they have an overview of the wider process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95275298",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "IBNR_Loss_Train_ijk <- function(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars, verbose = FALSE) {\n",
    "  \n",
    "  \n",
    "  # # debugging\n",
    "  # #~~~~~~~~~~~~~\n",
    "  # dt_policy_claim = dt_polclaim\n",
    "  # date_i = t_i\n",
    "  # j_dev_period = 1\n",
    "  # k = 1\n",
    "  # reserving_dates = lst_Date_slice\n",
    "  # model_vars <- IBNR_model_vars\n",
    "  # #~~~~~~~~~~~~~\n",
    "  \n",
    "  date_i <- as.Date(date_i)\n",
    "  date_k <- (reserving_dates[which(reserving_dates == date_i) - k + 1])\n",
    "  date_j <- (reserving_dates[which(reserving_dates == date_k) - j_dev_period])\n",
    "  date_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - j_dev_period -k + 1]) #i - j - k + 1 (predictor as at date)\n",
    "  target_lookup <- (reserving_dates[which(reserving_dates == (date_i)) - k]) #i - k to calculate target incremental paid\n",
    "  target_lookup_next <- (reserving_dates[which(reserving_dates == (date_i)) - k + 1]) #i -k + 1 to calculate targte incremental paid\n",
    "  \n",
    "  if(verbose) cat(paste(\"Valn date\", date_i, \", j = \", j_dev_period, \", k =\", k, \"\\n\"))\n",
    "  \n",
    "  dt_policy_claim <- dt_policy_claim[(date_lookup < date_report) & (date_occur < date_lookup) & (target_lookup >= date_pay  & date_pay < target_lookup_next)] #definition of reported but not settled\n",
    "  dt_policy_claim[, ':='(date_lookup = date_lookup,\n",
    "                         delay_train = as.numeric(date_lookup - date_pol_start), #extra feature\n",
    "                         j = j_dev_period,\n",
    "                         k = k,\n",
    "                         exposure = 1, #all claims trated equal\n",
    "                         \n",
    "                         target = ifelse(target_lookup >= date_pay & date_pay < target_lookup_next,claim_cost,0) #model assumes one payment so just need to check date paid\n",
    "                         \n",
    "  )]\n",
    "  \n",
    "  return(dt_policy_claim[, model_vars, with = FALSE])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9429170",
   "metadata": {},
   "source": [
    "### IBNR Test\n",
    "The code for creating the IBNR datasets is rather involved so detailed explanation has been skipped over here.  \n",
    "Interested readers are encouraged to come back to this stage and inspect the code and Baudry’s paper once they have an overview of the wider process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde13ca6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "IBNR_Test_ijk <- function(dt_policy_claim, date_i,j_dev_period, k, reserving_dates, model_vars, verbose = FALSE) {\n",
    "  \n",
    "  ## debugging\n",
    "  ##~~~~~~~~~~~~~\n",
    "  #dt_policy_claim = dt_polclaim\n",
    "  #date_i = t_i\n",
    "  #j_dev_period = 8\n",
    "  #k = 1\n",
    "  #reserving_dates = lst_Date_slice\n",
    "  #model_vars <- IBNR_model_vars\n",
    "  ##~~~~~~~~~~~~~\n",
    "  \n",
    "  date_i <- as.Date(date_i)\n",
    "  date_lookup <- (reserving_dates[which(reserving_dates == (date_i))]) #i - j - k + 1 (predictor as at date)\n",
    "  target_lookup <- (reserving_dates[which(reserving_dates == (date_i)) +j_dev_period - 1]) #i - k to calculate target incremental paid\n",
    "  target_lookup_next <- (reserving_dates[which(reserving_dates == (date_i)) + j_dev_period]) #i -k + 1 to calculate targte incremental paid  \n",
    "  \n",
    "  if(verbose) cat(paste(\"Valn date\", date_i, \", j = \", j_dev_period, \", k =\", k, \"\\n\"))\n",
    "  \n",
    "  # P_te_IBNR rowids of policies needing an RBNS reserve\n",
    "  dt_policy_claim <- dt_policy_claim[date_pol_start <= date_lookup & date_lookup < date_report] #IBNR\n",
    "  \n",
    "  dt_policy_claim[, ':='(date_lookup = date_lookup,\n",
    "                         delay_train = as.numeric(date_lookup - date_pol_start), #extra feature\n",
    "                         j = j_dev_period,\n",
    "                         k = k,\n",
    "                         exposure = round((pmin(as.numeric(as.numeric(date_pol_end)), as.numeric(floor_date(date_i, unit= \"second\")))\n",
    "                                             - as.numeric(date_pol_start))/(24*60*60*365),3),\n",
    "                         target = ifelse(target_lookup <= date_pay &  date_pay < target_lookup_next & date_occur <= date_lookup ,claim_cost,0))]  #model assumes one payment so just need to check date paid\n",
    "  \n",
    "  dt_policy_claim <- dt_policy_claim [,.(exposure = sum(exposure)), by= c(setdiff(model_vars, 'exposure')) ]\n",
    "  \n",
    "  return(dt_policy_claim[, model_vars, with = FALSE])\n",
    "  \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb63b0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67c0d44b",
   "metadata": {},
   "source": [
    "## IBNR function calls \n",
    "\n",
    "The IBNR train and test datasets are created by calling the `IBNR_Train` and `IBNR_Test` functions passing, as parameters to them, the names of the joined policy and claim dataset, valuation dates and model features. \n",
    "\n",
    "The functions  `IBNR_Train` and `IBNR_Test` iterate over valid values of j and k calling the `IBNR_Freq_ijk`, `IBNR_Loss_ijk` and `IBNR_Test_ijk` functions to create the complete train and test datasets as set out in the code below. \n",
    "\n",
    "The princple and code is similar to that of RBNS, except that the training data covers both claim counts and costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "163cb5d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "IBNR_Train <- function(dt_policy_claim, date_i, i, k, reserving_dates, model_vars, verbose = FALSE) {\n",
    "\n",
    "  # Create a combined TRAIN dataset across all k and j combos\n",
    "    for (k in 1:k){\n",
    "      if (k==1){\n",
    "        dt_train_Freq <- NULL\n",
    "        dt_train_Loss <- NULL\n",
    "      }\n",
    "      \n",
    "      for (j in 1:(i - k + 1)){\n",
    "        dt_train_Freq <- rbind(dt_train_Freq, IBNR_Freq_Train_ijk(dt_policy_claim, date_i, j, k,reserving_dates, model_vars, verbose))\n",
    "        dt_train_Loss <- rbind(dt_train_Loss, IBNR_Loss_Train_ijk(dt_policy_claim, date_i, j, k,reserving_dates, model_vars, verbose))\n",
    "      }\n",
    "    }\n",
    "\n",
    "  return(list(Freq = dt_train_Freq, Loss = dt_train_Loss))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63bea466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IBNR_Test <- function(dt_policy_claim, date_i, delta, k, reserving_dates, model_vars, verbose = FALSE) {\n",
    " \n",
    "  # Create a combined TEST dataset across all k and j combos\n",
    "  for (k in 1:k){\n",
    "    if (k==1) dt_test <- NULL\n",
    "    for (j in 1:(delta - k + 1)){\n",
    "      dt_test <- rbind(dt_test, IBNR_Test_ijk(dt_policy_claim, date_i, j, k,reserving_dates, model_vars, verbose))\n",
    "    }\n",
    "  }\n",
    "  return(dt_test)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6011801",
   "metadata": {},
   "source": [
    "So having given a rough outline of the data creation process lets now call the functions to create the IBNR datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24f77d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define IBNR modelVars\n",
    "IBNR_model_vars <- c(\"clm_number\",\n",
    "                     \"pol_number\",\n",
    "                     \"j\",\n",
    "                     \"k\",\n",
    "                     \"exposure\",\n",
    "                     \"date_pol_start\",\n",
    "                     \"date_occur\",\n",
    "                     \"date_report\",\n",
    "                     \"date_pay\",\n",
    "                     \"Cover\",\n",
    "                     \"Brand\",\n",
    "                     \"Model\",\n",
    "                     \"Price\",\n",
    "                     \"target\")\n",
    "    \n",
    "# Create a combined TRAIN dataset for k = 1 and all valid j delay values\n",
    "lst_IBNR_train <- IBNR_Train(dt_polclaim, t_i, i, k = 1,lst_Date_slice, IBNR_model_vars)\n",
    "\n",
    "# Create a combined TEST dataset for k = 1 and all valid j delay values\n",
    "dt_IBNR_test <- IBNR_Test(dt_polclaim, t_i, delta, k = 1,lst_Date_slice, IBNR_model_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e6c3f",
   "metadata": {},
   "source": [
    "The train and test datasets are then joined into a single dataset and a small amount of tidying is done to make them ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8f18538",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "lst_IBNR_train$Freq[, flgTrain := 1]\n",
    "lst_IBNR_train$Loss[, flgTrain := 2]\n",
    "dt_IBNR_test[, flgTrain := 0]\n",
    "\n",
    "dt_All_IBNR <- rbind(lst_IBNR_train$dt_train_Freq, lst_IBNR_train$dt_train_Loss, dt_IBNR_test)\n",
    "#write.csv(dt_All_IBNR,\"dt_All_IBNR.csv\", row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecc7c641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>limit (Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 1619093</td><td> 86.5</td><td>  3663570</td><td> 195.7</td><td>   NA</td><td>  3663570</td><td> 195.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>63896458</td><td>487.5</td><td>137735801</td><td>1050.9</td><td>16384</td><td>137583642</td><td>1049.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & limit (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  1619093 &  86.5 &   3663570 &  195.7 &    NA &   3663570 &  195.7\\\\\n",
       "\tVcells & 63896458 & 487.5 & 137735801 & 1050.9 & 16384 & 137583642 & 1049.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 7 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | limit (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Ncells |  1619093 |  86.5 |   3663570 |  195.7 |    NA |   3663570 |  195.7 |\n",
       "| Vcells | 63896458 | 487.5 | 137735801 | 1050.9 | 16384 | 137583642 | 1049.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used     (Mb)  gc trigger (Mb)   limit (Mb) max used  (Mb)  \n",
       "Ncells  1619093  86.5   3663570   195.7    NA        3663570  195.7\n",
       "Vcells 63896458 487.5 137735801  1050.9 16384      137583642 1049.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tidy up\n",
    "rm(lst_IBNR_train)\n",
    "rm(dt_IBNR_test)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64573e45",
   "metadata": {},
   "source": [
    "The important aspects of the tidying relate to creating useable delay metrics from the numerous dates and converting some character features such as cover and claim type into factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "168444a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order and create some delay fields\n",
    "setkey(dt_All_IBNR, clm_number, k, j)\n",
    "    \n",
    "dt_All_IBNR[, Count := .N , by =clm_number]\n",
    "dt_All_IBNR[,':='( delay_uw_occ = ifelse(year(date_occur) == 2199,\n",
    "                                        -1,\n",
    "                                        ceiling((as.numeric(date_occur) - as.numeric(date_pol_start))\n",
    "                                                  /(24*60*60))\n",
    "                                          ),\n",
    "                   delay_occ_rep = ifelse(year(date_occur) == 2199,\n",
    "                                          -1,\n",
    "                                          ceiling((as.numeric(date_report) - as.numeric(date_occur))\n",
    "                                                  /(24*60*60))\n",
    "                                          ),\n",
    "                   delay_rep_pay = ifelse(year(date_occur) == 2199,\n",
    "                                          -1,\n",
    "                                          ceiling((as.numeric(date_pay) - as.numeric(date_report))\n",
    "                                                  /(24*60*60))\n",
    "                                          ),\n",
    "                   delay_uw_val = ceiling((as.numeric(t_i) - as.numeric(date_pol_start))/(24*60*60)),\n",
    "                   date_uw = ceiling(as.numeric(date_pol_start)/(24*60*60)),\n",
    "                   Cover = as.factor(Cover))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604fcbc4",
   "metadata": {},
   "source": [
    "# Dataset inspection{.tabset}\n",
    "\n",
    "So we now have two datasets;\n",
    "\n",
    " * dt_ALL_RBNS for calculating RBNS reserves  \n",
    " * dt_ALL_IBNR for calculating IBNR reserves  \n",
    " \n",
    "Each dataset contains both training rows and test rows. The test rows are used for model prediction; which in this case means RBNS or IBNR reserve calculation. \n",
    "\n",
    "IBNR reserves are calculated using a frequency * severity model approach. IBNR therefore requires two models and two training datasets. Training rows for the claim frequency model are identified as rows with a flgTrain column value of 1. Training rows for the claim severity model are identified as rows with a flgTrain column value of 2.\n",
    "\n",
    "In both datsets the test rows are identified as rows with a flgTrain column value of 0.\n",
    "\n",
    "Let's have a quick look at the datasets. \n",
    "\n",
    "## RBNS\n",
    "\n",
    "The RBNS dataset has `r ncol(dt_All_RBNS)` columns and `r format(nrow(dt_All_RBNS), big.mark=\",\")` rows.\n",
    "\n",
    "In a traditional reserving exercise this would have been summarised as a 10 x 10 triangle ie 55 rows. We have far more rows of data for 3 main reasons;\n",
    "\n",
    "1. training data is presented without aggregation so there is a row for each one of the `r format(dt_polclaim[date_report <= t_i, sum(claim_count)],big.mark=\",\")` claims that have been reported up until `r t_i`\n",
    "2. the machine learning training dataset is not just the latest triangle of data as at the valuation date. It is also every possible historic triangle prior to the valuation date as illustrated in the animation above. \n",
    "3. the dataset also contains test rows ie the features needed to predict each future period from the current valuation date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62963838",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 21</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>clm_number</th><th scope=col>pol_number</th><th scope=col>j</th><th scope=col>k</th><th scope=col>date_pol_start</th><th scope=col>date_occur</th><th scope=col>date_report</th><th scope=col>date_pay</th><th scope=col>Cover</th><th scope=col>claim_type</th><th scope=col>⋯</th><th scope=col>Model</th><th scope=col>Price</th><th scope=col>target</th><th scope=col>flgTrain</th><th scope=col>Count</th><th scope=col>delay_uw_occ</th><th scope=col>delay_occ_rep</th><th scope=col>delay_uw_val</th><th scope=col>delay_rep_pay</th><th scope=col>date_uw</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>201601060001</td><td>201601050343</td><td>8</td><td>1</td><td>2016-01-05</td><td>2016-01-06</td><td>2016-01-06</td><td>2016-02-08</td><td>BOT</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>266</td><td>33</td><td>16805</td></tr>\n",
       "\t<tr><td>201601080001</td><td>201601040365</td><td>8</td><td>1</td><td>2016-01-04</td><td>2016-01-08</td><td>2016-01-08</td><td>2016-02-13</td><td>BOT</td><td>B</td><td>⋯</td><td>2</td><td>728</td><td>0</td><td>1</td><td>1</td><td>4</td><td>0</td><td>267</td><td>36</td><td>16804</td></tr>\n",
       "\t<tr><td>201601080002</td><td>201601040629</td><td>8</td><td>1</td><td>2016-01-04</td><td>2016-01-08</td><td>2016-01-08</td><td>2016-02-07</td><td>BO </td><td>B</td><td>⋯</td><td>2</td><td>728</td><td>0</td><td>1</td><td>1</td><td>4</td><td>0</td><td>267</td><td>30</td><td>16804</td></tr>\n",
       "\t<tr><td>201601090001</td><td>201601010222</td><td>8</td><td>1</td><td>2016-01-01</td><td>2016-01-09</td><td>2016-01-09</td><td>2016-02-05</td><td>BOT</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>1</td><td>1</td><td>8</td><td>0</td><td>270</td><td>27</td><td>16801</td></tr>\n",
       "\t<tr><td>201601090002</td><td>201601030514</td><td>8</td><td>1</td><td>2016-01-03</td><td>2016-01-07</td><td>2016-01-09</td><td>2016-02-09</td><td>BO </td><td>O</td><td>⋯</td><td>3</td><td>837</td><td>0</td><td>1</td><td>1</td><td>4</td><td>2</td><td>268</td><td>31</td><td>16803</td></tr>\n",
       "\t<tr><td>201601100001</td><td>201601010095</td><td>8</td><td>1</td><td>2016-01-01</td><td>2016-01-10</td><td>2016-01-10</td><td>2016-02-06</td><td>B  </td><td>B</td><td>⋯</td><td>3</td><td>837</td><td>0</td><td>1</td><td>1</td><td>9</td><td>0</td><td>270</td><td>27</td><td>16801</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 21\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " clm\\_number & pol\\_number & j & k & date\\_pol\\_start & date\\_occur & date\\_report & date\\_pay & Cover & claim\\_type & ⋯ & Model & Price & target & flgTrain & Count & delay\\_uw\\_occ & delay\\_occ\\_rep & delay\\_uw\\_val & delay\\_rep\\_pay & date\\_uw\\\\\n",
       " <chr> & <chr> & <int> & <int> & <dttm> & <dttm> & <dttm> & <dttm> & <fct> & <fct> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 201601060001 & 201601050343 & 8 & 1 & 2016-01-05 & 2016-01-06 & 2016-01-06 & 2016-02-08 & BOT & B & ⋯ & 3 & 913 & 0 & 1 & 1 & 1 & 0 & 266 & 33 & 16805\\\\\n",
       "\t 201601080001 & 201601040365 & 8 & 1 & 2016-01-04 & 2016-01-08 & 2016-01-08 & 2016-02-13 & BOT & B & ⋯ & 2 & 728 & 0 & 1 & 1 & 4 & 0 & 267 & 36 & 16804\\\\\n",
       "\t 201601080002 & 201601040629 & 8 & 1 & 2016-01-04 & 2016-01-08 & 2016-01-08 & 2016-02-07 & BO  & B & ⋯ & 2 & 728 & 0 & 1 & 1 & 4 & 0 & 267 & 30 & 16804\\\\\n",
       "\t 201601090001 & 201601010222 & 8 & 1 & 2016-01-01 & 2016-01-09 & 2016-01-09 & 2016-02-05 & BOT & B & ⋯ & 3 & 913 & 0 & 1 & 1 & 8 & 0 & 270 & 27 & 16801\\\\\n",
       "\t 201601090002 & 201601030514 & 8 & 1 & 2016-01-03 & 2016-01-07 & 2016-01-09 & 2016-02-09 & BO  & O & ⋯ & 3 & 837 & 0 & 1 & 1 & 4 & 2 & 268 & 31 & 16803\\\\\n",
       "\t 201601100001 & 201601010095 & 8 & 1 & 2016-01-01 & 2016-01-10 & 2016-01-10 & 2016-02-06 & B   & B & ⋯ & 3 & 837 & 0 & 1 & 1 & 9 & 0 & 270 & 27 & 16801\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 21\n",
       "\n",
       "| clm_number &lt;chr&gt; | pol_number &lt;chr&gt; | j &lt;int&gt; | k &lt;int&gt; | date_pol_start &lt;dttm&gt; | date_occur &lt;dttm&gt; | date_report &lt;dttm&gt; | date_pay &lt;dttm&gt; | Cover &lt;fct&gt; | claim_type &lt;fct&gt; | ⋯ ⋯ | Model &lt;dbl&gt; | Price &lt;dbl&gt; | target &lt;dbl&gt; | flgTrain &lt;dbl&gt; | Count &lt;int&gt; | delay_uw_occ &lt;dbl&gt; | delay_occ_rep &lt;dbl&gt; | delay_uw_val &lt;dbl&gt; | delay_rep_pay &lt;dbl&gt; | date_uw &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 201601060001 | 201601050343 | 8 | 1 | 2016-01-05 | 2016-01-06 | 2016-01-06 | 2016-02-08 | BOT | B | ⋯ | 3 | 913 | 0 | 1 | 1 | 1 | 0 | 266 | 33 | 16805 |\n",
       "| 201601080001 | 201601040365 | 8 | 1 | 2016-01-04 | 2016-01-08 | 2016-01-08 | 2016-02-13 | BOT | B | ⋯ | 2 | 728 | 0 | 1 | 1 | 4 | 0 | 267 | 36 | 16804 |\n",
       "| 201601080002 | 201601040629 | 8 | 1 | 2016-01-04 | 2016-01-08 | 2016-01-08 | 2016-02-07 | BO  | B | ⋯ | 2 | 728 | 0 | 1 | 1 | 4 | 0 | 267 | 30 | 16804 |\n",
       "| 201601090001 | 201601010222 | 8 | 1 | 2016-01-01 | 2016-01-09 | 2016-01-09 | 2016-02-05 | BOT | B | ⋯ | 3 | 913 | 0 | 1 | 1 | 8 | 0 | 270 | 27 | 16801 |\n",
       "| 201601090002 | 201601030514 | 8 | 1 | 2016-01-03 | 2016-01-07 | 2016-01-09 | 2016-02-09 | BO  | O | ⋯ | 3 | 837 | 0 | 1 | 1 | 4 | 2 | 268 | 31 | 16803 |\n",
       "| 201601100001 | 201601010095 | 8 | 1 | 2016-01-01 | 2016-01-10 | 2016-01-10 | 2016-02-06 | B   | B | ⋯ | 3 | 837 | 0 | 1 | 1 | 9 | 0 | 270 | 27 | 16801 |\n",
       "\n"
      ],
      "text/plain": [
       "  clm_number   pol_number   j k date_pol_start date_occur date_report\n",
       "1 201601060001 201601050343 8 1 2016-01-05     2016-01-06 2016-01-06 \n",
       "2 201601080001 201601040365 8 1 2016-01-04     2016-01-08 2016-01-08 \n",
       "3 201601080002 201601040629 8 1 2016-01-04     2016-01-08 2016-01-08 \n",
       "4 201601090001 201601010222 8 1 2016-01-01     2016-01-09 2016-01-09 \n",
       "5 201601090002 201601030514 8 1 2016-01-03     2016-01-07 2016-01-09 \n",
       "6 201601100001 201601010095 8 1 2016-01-01     2016-01-10 2016-01-10 \n",
       "  date_pay   Cover claim_type ⋯ Model Price target flgTrain Count delay_uw_occ\n",
       "1 2016-02-08 BOT   B          ⋯ 3     913   0      1        1     1           \n",
       "2 2016-02-13 BOT   B          ⋯ 2     728   0      1        1     4           \n",
       "3 2016-02-07 BO    B          ⋯ 2     728   0      1        1     4           \n",
       "4 2016-02-05 BOT   B          ⋯ 3     913   0      1        1     8           \n",
       "5 2016-02-09 BO    O          ⋯ 3     837   0      1        1     4           \n",
       "6 2016-02-06 B     B          ⋯ 3     837   0      1        1     9           \n",
       "  delay_occ_rep delay_uw_val delay_rep_pay date_uw\n",
       "1 0             266          33            16805  \n",
       "2 0             267          36            16804  \n",
       "3 0             267          30            16804  \n",
       "4 0             270          27            16801  \n",
       "5 2             268          31            16803  \n",
       "6 0             270          27            16801  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dt_All_RBNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6147e",
   "metadata": {},
   "source": [
    "## IBNR  \n",
    "  \n",
    "The IBNR dataset has `r ncol(dt_All_IBNR)` columns and `r format(nrow(dt_All_IBNR), big.mark=\",\")` rows.\n",
    "\n",
    "In a traditional reserving exercise this would have been summarised as a 10 x 10 triangle ie 50 rows. We have far more rows of data and far more that we did for the RBNS dataset.\n",
    "\n",
    "Again the the same 3 principles apply to the IBNR row count. However this will lead to many more rows of data  because we are training two models and the  claim frequency model will require a row for every past policy exposure period and of course there should be orders of magnitude more exposure rows than claim rows!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750716cf",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 6 × 21</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>clm_number</th><th scope=col>pol_number</th><th scope=col>j</th><th scope=col>k</th><th scope=col>exposure</th><th scope=col>date_pol_start</th><th scope=col>date_occur</th><th scope=col>date_report</th><th scope=col>date_pay</th><th scope=col>Cover</th><th scope=col>⋯</th><th scope=col>Model</th><th scope=col>Price</th><th scope=col>target</th><th scope=col>flgTrain</th><th scope=col>Count</th><th scope=col>delay_uw_occ</th><th scope=col>delay_occ_rep</th><th scope=col>delay_rep_pay</th><th scope=col>delay_uw_val</th><th scope=col>date_uw</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>NA</td><td>201601010002</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "\t<tr><td>NA</td><td>201601010003</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "\t<tr><td>NA</td><td>201601010004</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "\t<tr><td>NA</td><td>201601010005</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "\t<tr><td>NA</td><td>201601010006</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "\t<tr><td>NA</td><td>201601010007</td><td>1</td><td>1</td><td>0.74</td><td>2016-01-01</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>2199-12-31 23:59:59</td><td>B</td><td>⋯</td><td>3</td><td>913</td><td>0</td><td>0</td><td>1479120</td><td>-1</td><td>-1</td><td>-1</td><td>270</td><td>16801</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 6 × 21\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " clm\\_number & pol\\_number & j & k & exposure & date\\_pol\\_start & date\\_occur & date\\_report & date\\_pay & Cover & ⋯ & Model & Price & target & flgTrain & Count & delay\\_uw\\_occ & delay\\_occ\\_rep & delay\\_rep\\_pay & delay\\_uw\\_val & date\\_uw\\\\\n",
       " <chr> & <chr> & <int> & <int> & <dbl> & <dttm> & <dttm> & <dttm> & <dttm> & <fct> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t NA & 201601010002 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\t NA & 201601010003 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\t NA & 201601010004 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\t NA & 201601010005 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\t NA & 201601010006 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\t NA & 201601010007 & 1 & 1 & 0.74 & 2016-01-01 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & 2199-12-31 23:59:59 & B & ⋯ & 3 & 913 & 0 & 0 & 1479120 & -1 & -1 & -1 & 270 & 16801\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 6 × 21\n",
       "\n",
       "| clm_number &lt;chr&gt; | pol_number &lt;chr&gt; | j &lt;int&gt; | k &lt;int&gt; | exposure &lt;dbl&gt; | date_pol_start &lt;dttm&gt; | date_occur &lt;dttm&gt; | date_report &lt;dttm&gt; | date_pay &lt;dttm&gt; | Cover &lt;fct&gt; | ⋯ ⋯ | Model &lt;dbl&gt; | Price &lt;dbl&gt; | target &lt;dbl&gt; | flgTrain &lt;dbl&gt; | Count &lt;int&gt; | delay_uw_occ &lt;dbl&gt; | delay_occ_rep &lt;dbl&gt; | delay_rep_pay &lt;dbl&gt; | delay_uw_val &lt;dbl&gt; | date_uw &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| NA | 201601010002 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "| NA | 201601010003 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "| NA | 201601010004 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "| NA | 201601010005 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "| NA | 201601010006 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "| NA | 201601010007 | 1 | 1 | 0.74 | 2016-01-01 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | 2199-12-31 23:59:59 | B | ⋯ | 3 | 913 | 0 | 0 | 1479120 | -1 | -1 | -1 | 270 | 16801 |\n",
       "\n"
      ],
      "text/plain": [
       "  clm_number pol_number   j k exposure date_pol_start date_occur         \n",
       "1 NA         201601010002 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "2 NA         201601010003 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "3 NA         201601010004 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "4 NA         201601010005 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "5 NA         201601010006 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "6 NA         201601010007 1 1 0.74     2016-01-01     2199-12-31 23:59:59\n",
       "  date_report         date_pay            Cover ⋯ Model Price target flgTrain\n",
       "1 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "2 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "3 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "4 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "5 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "6 2199-12-31 23:59:59 2199-12-31 23:59:59 B     ⋯ 3     913   0      0       \n",
       "  Count   delay_uw_occ delay_occ_rep delay_rep_pay delay_uw_val date_uw\n",
       "1 1479120 -1           -1            -1            270          16801  \n",
       "2 1479120 -1           -1            -1            270          16801  \n",
       "3 1479120 -1           -1            -1            270          16801  \n",
       "4 1479120 -1           -1            -1            270          16801  \n",
       "5 1479120 -1           -1            -1            270          16801  \n",
       "6 1479120 -1           -1            -1            270          16801  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dt_All_IBNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124d227",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "I've deliberately rushed through the creation of the datasets so we can see the end output shown above. Interested readers are encouraged to revisit and review the RBNS and IBNER data creation process to gain a deeper understanding. In doing so they will be better placed to adapt the code provided to their own circumstances. \n",
    "\n",
    "To aid that deeper understanding, if you wish to try out this code in your own local instance of R then we have made this code and the supporting files and folders available in a zip file [here](/mlr-blog/l_baudry/Baudry_2.zip).\n",
    "\n",
    "Download and extract the zip file to a local directory and then open the R project file `Baudry_2.rproj` in your local R software installation. In the root of the project folder you will see two files;  \n",
    "\n",
    "1. Notebook_2_CreateReservingDatabase_v1.Rmd - which is the source code used to recreate this notebook\n",
    "2. Notebook_2_CreateReservingDatabase_v1.R - the equivalent code provided as an R script\n",
    "\n",
    "Please note that, depending upon your R installation , you may have to install R libraries before you can run the code provided. R will warn you if you have missing dependencies and you can then install them from CRAN.\n",
    "\n",
    "The above code can be wrapped into a series of functions which, given a  joined policy and claim dataset and a valuation date, will return the reserving datasets needed for machine learning. In notebook 3 of this series we will create and use such functions prior to fitting a machine learning model to the training data and then use it to make reserve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22d881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "out.height,fig.align,fig.cap,out.width,echo,tags,fig.show,language,-all",
   "formats": "Rmd,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
