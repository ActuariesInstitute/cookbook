
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Py: Text Classification &#8212; Actuaries&#39; Analytical Cookbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Automated Decision-Making Systems" href="automated_decision.html" />
    <link rel="prev" title="R: Word Cloud Case Study" href="R_case_study_word_cloud.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/actuaries-logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Actuaries' Analytical Cookbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption" role="heading">
 <span class="caption-text">
  Introduction to Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="about_py.html">
   About Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_by_example.html">
   An Introductory Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learn_more.html">
   Learn More
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Introduction to R
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="about_R.html">
   About R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started_R.html">
   Setting Up R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="introductory_R.html">
   Introduction to R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intermediate_R.html">
   Next Steps With R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="top_ten_r_packages.html">
   Useful Packages
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Workflow Management
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="version_control.html">
   Version control
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Segmentation and Technical Price
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="multitasking_risk_pricing.html">
   Py/R: Multitasking Risk Pricing Using Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_shap_values.html">
   Py: Explainable Models with SHAP
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="R_case_study_word_cloud.html">
   R: Word Cloud Case Study
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Py: Text Classification
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Data Ethics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="automated_decision.html">
   Automated Decision-Making Systems
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Useful Python Packages
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Useful_Python_packages.html">
   Useful Python packages for Data Science
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/textClassificationEntry.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ActuariesInstitute/cookbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        <a class="edit-button" href="https://github.com/ActuariesInstitute/cookbook/edit/main/cookbook/docs/textClassificationEntry.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ActuariesInstitute/cookbook/main?urlpath=tree/cookbook/docs/textClassificationEntry.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ActuariesInstitute/cookbook/blob/main/cookbook/docs/textClassificationEntry.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools-and-packages">
   Tools and Packages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-the-code-from-your-browser">
   Run the code from your browser
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-and-cleaning-data">
   Importing and Cleaning Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-extraction">
   Feature Extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words-bow-model">
     Bag of Words (BOW) Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression-classifier">
   Logistic Regression Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#afterward">
   Afterward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-analysis">
   Further Analysis
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="py-text-classification">
<h1>Py: Text Classification<a class="headerlink" href="#py-text-classification" title="Permalink to this headline">¶</a></h1>
<p>By Jonathan Tan. Originally published in Actuaries Digital as <a class="reference external" href="https://www.actuaries.digital/2018/11/20/analytics-snippet-natural-language-processing-text-classification/">Analytics Snippet: Natural Language Processing Text Classification</a>.</p>
<p>According to an article written by <a class="reference external" href="https://www.ibm.com/blogs/watson/2016/05/biggest-data-challenges-might-not-even-know/">IBM</a>, it is estimated at 80% of all data is unstructured. Unstructured data is the messy stuff every quantitative analyst tries to traditionally stay away from. It can include images of accidents, text notes of loss adjusters, social media comments, claim documents and review of medical doctors etc. How can actuaries make use of these kinds of data to add value to the insurer and what techniques are available for handling these types of data? <br><br>
In the insurance industry, text data appears everywhere but is generally more prevalent in the marketing, sales and claims. Listed below are some of the possible areas in which an insurer can benefit from text data analytics: <br><br></p>
<ul class="simple">
<li><p><strong>General Insurance</strong></p></li>
<li><p>Sentiment analysis from customer feedback</p></li>
<li><p>Chatbots for product recommendations and customer service</p></li>
<li><p>Automation of claims management process</p></li>
<li><p><strong>Life Insurance</strong></p></li>
<li><p>Increase accuracy of underwriting process with the use of context analysis from social media platforms</p></li>
<li><p>Improved customer service through timely responses on coverage, billing ect. especially with the massive library of PDSes</p></li>
<li><p><strong>Investments</strong></p></li>
<li><p>Recommendation systems based on risk appetite identification from client conversations</p></li>
</ul>
<br>
In this article, we are going to be looking at one of the topics within Natural Language Processing: Text Classification. The way we are going to handle this problem can be split into 3 distinct parts: <br>
1. Importing and cleaning the dataset <br>
2. Transforming text to numerical features <br>
3. Classifying the complaints using supervised learning techniques<div class="section" id="tools-and-packages">
<h2>Tools and Packages<a class="headerlink" href="#tools-and-packages" title="Permalink to this headline">¶</a></h2>
<p>The article uses <a class="reference external" href="https://www.python.org/">Python3</a> and the main packages that we will be using are listed below:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pandas.pydata.org/">Pandas</a> and <a class="reference external" href="http://www.numpy.org/">Numpy</a> for general data manipulation</p></li>
<li><p><a class="reference external" href="https://matplotlib.org/">Matplotlib</a> and <a class="reference external" href="https://seaborn.pydata.org/">Seaborn</a> for general data visualisation</p></li>
<li><p><a class="reference external" href="http://scikit-learn.org/stable/">Sci-kit</a> learn packages for both feature extraction and classification model</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">pq</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="run-the-code-from-your-browser">
<h2>Run the code from your browser<a class="headerlink" href="#run-the-code-from-your-browser" title="Permalink to this headline">¶</a></h2>
<p>The python code in this snippet can be run from your browser through this <a class="reference external" href="https://mybinder.org/v2/gh/jtsw1990/articles.git/master?filepath=textClassificationEntry.ipynb">link</a>. <br><br>
As with the other articles, loading time is to be expected. However, the binder does not require the reader to download the dataset, or any other dependencies to run the models. Furthermore, the reader is encouraged to play around with the code and use a different classification model to get more accurate results than the one presented here!</p>
</div>
<div class="section" id="importing-and-cleaning-data">
<h2>Importing and Cleaning Data<a class="headerlink" href="#importing-and-cleaning-data" title="Permalink to this headline">¶</a></h2>
<p>The dataset we are using here consists of information regarding finance related complaints that a company has received from its customers.
It is provided by an open source data library managed by the U.S. General Services Administration and can be downloaded <a class="reference external" href="https://catalog.data.gov/dataset/consumer-complaint-database">here</a>.
<br><br>
Since we are trying to predict the category of products based on the complaints received, we can ignore the rest of the columns for the purposes of this exercise and only focus at 2 of them, in particular:</p>
<ul class="simple">
<li><p>Description - Narrative of customer’s complaint</p></li>
<li><p>Product - The category of financial products which the complaint relates to
<br><br></p></li>
</ul>
<p>We will also get rid of null entries as they will not be of any use to us.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://www.dropbox.com/s/9whncsovtccbgx8/Consumer_complaints.parquet?dl=1&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Consumer complaint narrative&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notnull</span><span class="p">()),</span> <span class="p">[</span><span class="s1">&#39;Consumer complaint narrative&#39;</span><span class="p">,</span> <span class="s1">&#39;Product&#39;</span><span class="p">]]</span> \
       <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> \
       <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Product</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)))</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Product</span> <span class="o">!=</span> <span class="s1">&#39;Credit card or prepaid card&#39;</span><span class="p">)]</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">250</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>description</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I have outdated information on my credit report that I have previously disputed that has yet to be removed this information is more then seven years old and does not meet credit reporting requirements</td>
      <td>Credit reporting</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I purchased a new car on XXXX XXXX. The car dealer called Citizens Bank to get a 10 day payoff on my loan, good till XXXX XXXX. The dealer sent the check the next day. When I balanced my checkbook on XXXX XXXX. I noticed that Citizens bank had ta...</td>
      <td>Consumer Loan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>An account on my credit report has a mistaken date. I mailed in a debt validation letter to allow XXXX to correct the information. I received a letter in the mail, stating that Experian received my correspondence and found it to be " suspicious '...</td>
      <td>Credit reporting</td>
    </tr>
    <tr>
      <th>3</th>
      <td>This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.</td>
      <td>Debt collection</td>
    </tr>
    <tr>
      <th>4</th>
      <td>This complaint is in regards to Square Two Financial. Refer to CFPB case number XXXX regarding CACH, L. L. C. Square Two Financial has utilized my entire social security number to include date of birth on the pfd document listed with this complai...</td>
      <td>Debt collection</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Next, we will assign each target variable an integer value instead of using the string representation (Credit reporting for example). This allows our models to be able to recognize the responses. We can do this using a variety of methods, but here we will be using sklearn’s LabelEncoder function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">encoded_response</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
<span class="n">df</span><span class="p">[[</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;encoded_response&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">()</span> \
                                  <span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">)</span> \
                                  <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;encoded_response&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>encoded_response</th>
    </tr>
    <tr>
      <th>target</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bank account or service</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Checking or savings account</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Consumer Loan</th>
      <td>2</td>
    </tr>
    <tr>
      <th>Credit card</th>
      <td>3</td>
    </tr>
    <tr>
      <th>Credit reporting</th>
      <td>4</td>
    </tr>
    <tr>
      <th>Debt collection</th>
      <td>5</td>
    </tr>
    <tr>
      <th>Money transfers</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Mortgage</th>
      <td>7</td>
    </tr>
    <tr>
      <th>Other financial service</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Payday loan</th>
      <td>9</td>
    </tr>
    <tr>
      <th>Prepaid card</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Student loan</th>
      <td>11</td>
    </tr>
    <tr>
      <th>Vehicle loan or lease</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Virtual currency</th>
      <td>13</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see from the output above, that our resulting dataset contains 14 unique categories which we will try to classify complaints into by training our model to “understand” the narrative. <br><br>
After encoding our target variable, we can then move on to splitting our dataset for training and validation purposes. Train test splits are a crucial part of any modelling process and prevents <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>. Here, we are using an 80/20 split and setting a random seed for reproducibility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">indices_train</span><span class="p">,</span> <span class="n">indices_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">description</span><span class="p">,</span> 
                                                                                 <span class="n">df</span><span class="o">.</span><span class="n">encoded_response</span><span class="p">,</span>
                                                                                 <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                                                                                 <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> 
                                                                                 <span class="n">random_state</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="feature-extraction">
<h2>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this headline">¶</a></h2>
<p>Just as we have encoded our target variables, we must also find a way to transform our description data out if its string representation into a numerical one. However, unlike the target variables, this process is not as simple as allocating an integer value to each unique complaint. Keep in mind that a meaningful transformation must somehow display some form of homogeneity between complaints within the same product categories.</p>
<div class="section" id="bag-of-words-bow-model">
<h3>Bag of Words (BOW) Model<a class="headerlink" href="#bag-of-words-bow-model" title="Permalink to this headline">¶</a></h3>
<p>One way of transforming a document full of text data into numerical features is by using the BOW (Bag of Words) model. Put simply, all it does is assign each unique word (or token) an ID number and counts up its frequency. For example, if we have a document: <br><br>
<code class="docutils literal notranslate"><span class="pre">&quot;This</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">cat.</span> <span class="pre">That</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">dog&quot;</span></code>
<br><br>
The BOW representation would simply be: <br><br>
<code class="docutils literal notranslate"><span class="pre">BOW</span> <span class="pre">=</span> <span class="pre">{&quot;This&quot;:</span> <span class="pre">1,</span> <span class="pre">&quot;is&quot;:</span> <span class="pre">2,</span> <span class="pre">&quot;a&quot;:</span> <span class="pre">2,</span> <span class="pre">&quot;cat&quot;</span> <span class="pre">:</span> <span class="pre">1,</span> <span class="pre">&quot;That&quot;</span> <span class="pre">:</span> <span class="pre">1,</span> <span class="pre">&quot;dog&quot;</span> <span class="pre">:</span> <span class="pre">1}</span></code>
<br><br>
Notice that the document shown above is clearly about a cat and a dog. However, our BOW model shows that the most frequent words present in the document are “is” and “a”. These common words are also known as <a class="reference external" href="https://en.wikipedia.org/wiki/Stop_words">“stop words”</a> and are usually filtered out of the BOW model during the pre-processing phase to prevent overpowering the words that have actual importance. There are many different little tricks and techniques for choosing the most suitable bag of words to represent your documents and most can be implemented simply through a line (or two) of code using <a class="reference external" href="https://docs.python.org/2/library/re.html">regular expressions</a>, which is a great way to filter texts and I highly recommend getting comfortable with using them.<br><br>
How does this link back to the goal of having numerical features as our inputs? Imagine having a thousand text documents and extracting all (a subset) of the unique tokens that we think best represents them. Now, we can assign each unique token to a column in a dataframe and populate the rows with each document’s count of the respective words. Following the example above, our single document would produce a dataframe that looks like: <br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;This&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
              <span class="s2">&quot;That&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>This</th>
      <th>is</th>
      <th>a</th>
      <th>cat</th>
      <th>That</th>
      <th>dog</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Realistically, if we had chosen 15,000 unique tokens from the 1000 documents, our input matrix would then have 15,000 columns! You can start to imagine how sparse (full of zeros) our resulting input matrix will be! This technique is also commonly known as count vectorizing. <br><br>
In this article however, we will be using a more robust model compared to count vectorizing called (TF-IDF) Term Frequency - Inverse Document Frequency, and it is defined as:</p>
<p><span class="math notranslate nohighlight">\(w_{i,j} = tf_{i,j} * log(\dfrac{N}{df_i})\)</span>
<br><br>
<span class="math notranslate nohighlight">\(w_{i,j}\)</span> = Weight for word(i) in document(j) <br>
<span class="math notranslate nohighlight">\(tf_{i,j}\)</span> = Count of word(i) in document(j) <br>
<span class="math notranslate nohighlight">\(N\)</span> = Total number of documents <br>
<span class="math notranslate nohighlight">\(df_i\)</span> = How many documents word(i) appears in<br><br></p>
<p>We can see that, the first term of the TF-IDF model is just the count of the word in the document as before. The magic happens in the second term where the model imposes an additional condition for a word to be deemed “important”. Just as an example, if the word “bank” appears in every single document, it wouldn’t be of much use in differentiating the documents, and the second term of the TF-IDF model expresses this by reducing the whole weight down to 0. For a more detailed explanation on how TF-IDF works, there is an article written at <a class="reference external" href="https://www.elephate.com/blog/what-is-tf-idf/">elephate.com</a> explaining it quite elegantly.</p>
<p>There are a variety of packages that help to automate the vectorizing process, but we have chosen to use the Sci-kit learn API due to its easy of usage and interpretability. Here, we instantiate a TfidfVectorizer model, with a few note-worthy details: <br></p>
<ul class="simple">
<li><p>Sublinear_tf uses a logarithmic form of frequency as 20 occurrences of a word does not imply 20 times the importance in most cases <br></p></li>
<li><p>The model will ignore words that appear in less than 5 documents, as well as more than 70% of the total documents <br></p></li>
<li><p>Normalization is set to L2 (Not to be confused with L2 regularisation) so that all vectors are scaled to have a magnitude of 1 (The equivalent of standardizing your features) <br></p></li>
<li><p>There is a layer of pre-processing to remove numerical characters and symbols within the documents using a regular expression (REGEX)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">sublinear_tf</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
                                   <span class="n">stop_words</span> <span class="o">=</span> <span class="s1">&#39;english&#39;</span><span class="p">,</span>
                                   <span class="n">min_df</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                   <span class="n">max_df</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>
                                   <span class="n">norm</span> <span class="o">=</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                                   <span class="n">token_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;\b[^_\d\W]+\b&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We then use the model to fit our original description data, and convert all that sweet text information into something numerical!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_train</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">tfidf_test</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19285
</pre></div>
</div>
</div>
</div>
<p>We can see that our resulting dictionary consists of 19,285 different unique words!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">SparseDataFrame</span><span class="p">(</span><span class="n">tfidf_train</span><span class="p">,</span> 
                              <span class="n">columns</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(),</span>
                              <span class="n">copy</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">tfidf_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aa</th>
      <th>aaa</th>
      <th>aaddress</th>
      <th>aadvantage</th>
      <th>aafes</th>
      <th>...</th>
      <th>zone</th>
      <th>zoned</th>
      <th>zones</th>
      <th>zoning</th>
      <th>zwicker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 19285 columns</p>
</div></div></div>
</div>
<p>As mentioned above, the 19,285 words chosen to be in our “dictionary” become the columns of our input matrix and just to reiterate, since we have so many columns and each row only consists of words within 1 document, the resulting matrix will be extremely sparse! (Consisting mostly of zeros) <br><br>
Now that we have extracted some numerical features from our dataset, it is time to use them to train a classifier!</p>
</div>
</div>
<div class="section" id="logistic-regression-classifier">
<h2>Logistic Regression Classifier<a class="headerlink" href="#logistic-regression-classifier" title="Permalink to this headline">¶</a></h2>
<p>In this example, we have chosen to use a basic <a class="reference external" href="http://www.appstate.edu/~whiteheadjc/service/logit/intro.htm">logistic regression model</a> to classify the documents due to tractability and convention. However, more complex models such as neural networks, decision trees, naive bayesian classifiers or other relevant models can also be used to do the following classification and the reader is encouraged to try different machine learning models to see which ones give the most accurate results! <br><br>
Firstly, we instantiate a logistic regression classifier from the sklearn package and proceed to fit our TF-IDF vectorized matrix and our encoded training labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_classifier</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">lr_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tfidf_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</div>
</div>
</div>
<p>We can observe that amongst the model parameters, sklearn has automatically set ‘penalty’ to L2. This is a form of regularization, which weighs the benefits of a better fit against using more features by adding an extra term to the objective function. Coursera does quite a good job in explaining what L2 regularization in logisitic regression means <a class="reference external" href="https://www.coursera.org/lecture/ml-classification/l2-regularized-logistic-regression-DBTNt">here</a>. Recall that when using the BOW model, we ended up creating thousands of features. Adding regularization to our model would then help to prevent creating too many of them!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">tfidf_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">lr_classifier</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">coefficients</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">,</span> <span class="s1">&#39;coefficients&#39;</span><span class="p">]</span>
<span class="n">coefficients</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>coefficients</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aa</td>
      <td>-0.064147</td>
    </tr>
    <tr>
      <th>1</th>
      <td>aaa</td>
      <td>-0.422178</td>
    </tr>
    <tr>
      <th>2</th>
      <td>aaddress</td>
      <td>-0.019091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aadvantage</td>
      <td>0.808569</td>
    </tr>
    <tr>
      <th>4</th>
      <td>aafes</td>
      <td>-0.143279</td>
    </tr>
    <tr>
      <th>5</th>
      <td>aag</td>
      <td>-0.051489</td>
    </tr>
    <tr>
      <th>6</th>
      <td>aand</td>
      <td>-0.063603</td>
    </tr>
    <tr>
      <th>7</th>
      <td>aargon</td>
      <td>-0.150654</td>
    </tr>
    <tr>
      <th>8</th>
      <td>aarp</td>
      <td>-0.069611</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ab</td>
      <td>-0.261654</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Since we have converted all our “text” data into numerical features, we can view the weights and features just as we would be able to for any other logisitic regression model on numerical data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">lr_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">tfidf_test</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8517154487303741
</pre></div>
</div>
</div>
</div>
<p>After running the model on the validation set, we can see that we attained some pretty decent results with an overall accuracy of 85.2% with just a simple logistic regression classifier. We can drill down into this result by evaluating the <a class="reference external" href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology">confusion matrix</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Due to the huge imbalance of data points between the different categories, the resulting figures in the confusion matrix are normalized to produce clearer distinctions between “good” and “poor” performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> 
            <span class="n">annot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
            <span class="n">fmt</span> <span class="o">=</span> <span class="s2">&quot;.3f&quot;</span><span class="p">,</span> 
            <span class="n">linewidths</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> 
            <span class="n">square</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
            <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;Reds&#39;</span><span class="p">,</span> 
            <span class="n">xticklabels</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
            <span class="n">yticklabels</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">all_sample_title</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">all_sample_title</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5,1,&#39;Accuracy Score: 0.8517154487303741&#39;)
</pre></div>
</div>
<img alt="../_images/textClassificationEntry_39_1.png" src="../_images/textClassificationEntry_39_1.png" />
</div>
</div>
<p>One of the more obvious results we can observe just from diagonals of the matrix is that “Other financial service”, “Vehicle loan or lease” and “Virtual currency” categories had no correct predictions. We must note however, that the number of data points we had for each of these categories were insignificant compared to the others and the model probably treated those instances as errors instead of a distinct category. This bias however, can be corrected by techniques such as <a class="reference external" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis">over and undersampling</a>. Let’s investigate further to see if the model does indeed treat the documents within these categories as errors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">report2dict</span><span class="p">(</span><span class="n">cr</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Function solely for formatting purposes, can be ignored&#39;&#39;&#39;</span>
    
    <span class="n">tmp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">cr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">):</span>
        <span class="n">parsed_row</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">row</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;  &quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parsed_row</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tmp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parsed_row</span><span class="p">)</span>
    <span class="n">measures</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">D_class_data</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tmp</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">class_label</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measures</span><span class="p">):</span>
            <span class="n">D_class_data</span><span class="p">[</span><span class="n">class_label</span><span class="p">][</span><span class="n">m</span><span class="o">.</span><span class="n">strip</span><span class="p">()]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">D_class_data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span>
                                     <span class="n">target_names</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">report2dict</span><span class="p">(</span><span class="n">results</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\users\jtan\appdata\local\continuum\anaconda3\lib\site-packages\sklearn\metrics\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  &#39;precision&#39;, &#39;predicted&#39;, average, warn_for)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>f1-score</th>
      <th>precision</th>
      <th>recall</th>
      <th>support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bank account or service</th>
      <td>0.78</td>
      <td>0.76</td>
      <td>0.81</td>
      <td>2965.0</td>
    </tr>
    <tr>
      <th>Checking or savings account</th>
      <td>0.22</td>
      <td>0.98</td>
      <td>0.12</td>
      <td>424.0</td>
    </tr>
    <tr>
      <th>Consumer Loan</th>
      <td>0.67</td>
      <td>0.73</td>
      <td>0.63</td>
      <td>1884.0</td>
    </tr>
    <tr>
      <th>Credit card</th>
      <td>0.81</td>
      <td>0.80</td>
      <td>0.83</td>
      <td>3696.0</td>
    </tr>
    <tr>
      <th>Credit reporting</th>
      <td>0.87</td>
      <td>0.88</td>
      <td>0.86</td>
      <td>6240.0</td>
    </tr>
    <tr>
      <th>Debt collection</th>
      <td>0.87</td>
      <td>0.84</td>
      <td>0.90</td>
      <td>9600.0</td>
    </tr>
    <tr>
      <th>Money transfers</th>
      <td>0.68</td>
      <td>0.76</td>
      <td>0.61</td>
      <td>301.0</td>
    </tr>
    <tr>
      <th>Mortgage</th>
      <td>0.94</td>
      <td>0.92</td>
      <td>0.96</td>
      <td>7359.0</td>
    </tr>
    <tr>
      <th>Other financial service</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>Payday loan</th>
      <td>0.49</td>
      <td>0.71</td>
      <td>0.37</td>
      <td>342.0</td>
    </tr>
    <tr>
      <th>Prepaid card</th>
      <td>0.68</td>
      <td>0.81</td>
      <td>0.59</td>
      <td>283.0</td>
    </tr>
    <tr>
      <th>Student loan</th>
      <td>0.91</td>
      <td>0.91</td>
      <td>0.90</td>
      <td>2765.0</td>
    </tr>
    <tr>
      <th>Vehicle loan or lease</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>186.0</td>
    </tr>
    <tr>
      <th>Virtual currency</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>avg / total</th>
      <td>0.84</td>
      <td>0.85</td>
      <td>0.85</td>
      <td>36113.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that calling the classification_report function actually produces a <em>UndefinedMetricWarning</em> but what does this mean? <br><br>
If we look deeper into this, the error tells us that the model, made no predictions (correctly or incorrectly) for those 3 categories, which supports the hypothesis we made earlier that these documents were just treated as errors! Since we now roughly know the reasons for misclassifications in these 3 categories, let’s try to look at a category where data points were not sparse and try to find an explanation for those misclassified documents. <br><br>
Shown below are some examples where ‘Checking and savings account’ narratives were wrongly classified as ‘Bank account and service’.</p>
<p>Categories with more data points generally had a better score, and the reasons for misclassifications in these categories seem to follow the trend of overlapping categories. (For example, 320 descriptions that were supposed to be “Checking and savings account” related were wrongly classified as “Bank account and service”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">observe_errors</span><span class="p">(</span><span class="n">actual_response</span><span class="p">,</span> <span class="n">wrongly_predicted_response</span><span class="p">):</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span> <span class="o">=</span> <span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span> <span class="o">=</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
    <span class="n">compare</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;actual&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted&#39;</span><span class="p">])</span>
    <span class="n">compare</span> <span class="o">=</span> <span class="n">compare</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">actual_product</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">actual</span><span class="p">),</span>
                             <span class="n">predicted_product</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">predicted</span><span class="p">))</span> \
                     <span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">compare</span><span class="o">.</span><span class="n">actual</span> <span class="o">==</span> <span class="n">actual_response</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">compare</span><span class="o">.</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">wrongly_predicted_response</span><span class="p">),</span>
                         <span class="p">[</span><span class="s1">&#39;description&#39;</span><span class="p">,</span> <span class="s1">&#39;actual_product&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_product&#39;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">compare</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observe_errors</span><span class="p">(</span><span class="n">actual_response</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">wrongly_predicted_response</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>description</th>
      <th>actual_product</th>
      <th>predicted_product</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35632</th>
      <td>On Saturday morning around   XXXX   XXXX  , I went to the Chase Bank #  XXXX  on  XXXX   XXXX   XXXX   XXXX  in  XXXX , Texas to try to open an savings account. I was received by the Teller I asked her nicely that I wanted to open an savings acco...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35748</th>
      <td>PNC bank changed the terms on my bank account a second time without notifying me. The first change would prevent me from ever having a transaction in the bank with a human being without being charged a fee. I learned about this issue after findin...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35835</th>
      <td>On  XXXX   XXXX ,  2017 , I deposited several checks into my checking account, one of which was in excess of {$5000.00}. The branch manager put a hold on this check thereby making these funds unavailable to me for the purpose to which they were i...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35870</th>
      <td>I did a complaint to Bank of America, because  XXXX  charge withdraw money from my account, one year ago my daughter call  XXXX  for do a question, but we decided do not use  XXXX  because a Mistake the company withdraw money from my bank account...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>36085</th>
      <td>I opened a PMA checking and brokerage account with  Wells Fargo  in  XXXX .   I had  XXXX  checking account, a credit card and ATM card at that time.     At some point in  XXXX , inexplicably, a second checking account appeared on my statements. ...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that the misclassified complaints shown above is quite ambiguous and contain ideas and keywords within the narrative related to both categories, which is presumably why the model would have misclassified them.</p>
<p>Because of the how text data is converted into numerical features, data pre-processing is an extremely important step when it comes to NLP problems and the “garbage-in, garbage-out” property can be very prevalent compared to other machine learning techniques. Also note that, in this problem that there are existing labels in the dataset, and we could have just as easily used any other supervised learning techniques to classify the documents. If, however, no labels are available, we would then have to turn towards unsupervised learning algorithms such as SVM, K-means or LDA to try and cluster the documents into sensible categories.</p>
</div>
<div class="section" id="afterward">
<h2>Afterward<a class="headerlink" href="#afterward" title="Permalink to this headline">¶</a></h2>
<p>We have essentially just taught the computer how to “understand” a small selected group of documents in a very human way with approximately 50 lines of code (ignoring the functions for visualisation)! Regardless of whether you are working in (or plan to work in) the general insurance, life insurance, health insurance or investments sector, text data is a big part of the business, and with the ever-growing focus on customer satisfaction, the need for actuaries to learn how to deal with this data type will be an integral part of dealing with uncertainty. <br><br>
For more resources on Natural Language Processing techniques, I highly recommend <a class="reference external" href="http://blog.aylien.com/12-of-the-best-free-natural-language-processing-and-machine-learning-educational-resources/">AYLIEN</a>, which is a data science blog that provides quite a comprehensive list of learning material from journal articles, lectures and videos for both beginners and advanced practitioners.</p>
<p>If you are interested in other machine learning models and its applications in the insurance industry, you can check out Jacky’s previous Analytics Snippet “Multitasking Risk Pricing Using Deep Learning” <a class="reference external" href="https://www.actuaries.digital/2018/08/23/analytics-snippet-multitasking-risk-pricing-using-deep-learning/">here</a>.</p>
</div>
<div class="section" id="further-analysis">
<h2>Further Analysis<a class="headerlink" href="#further-analysis" title="Permalink to this headline">¶</a></h2>
<p>If you would like to further explore the capabilities of different BOW and classification models using this dataset, <a class="reference external" href="https://www.kaggle.com/sebastienverpile/consumercomplaintsdata/home">Kaggle</a> provides an outlet to publish your results and discuss them with others!</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ActuariesInstitute/cookbook",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="R_case_study_word_cloud.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">R: Word Cloud Case Study</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="automated_decision.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Automated Decision-Making Systems</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By YDAWG, DAPC, YAC and other contributors. The Institute wishes it to be understood that any opinions put forward in this publication are not necessarily those of the Institute.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>