
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Py: Text Classification &#8212; Actuaries&#39; Analytical Cookbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Py: Decision Tree Classification" href="DAA_M05_Ex10.html" />
    <link rel="prev" title="R: Word Cloud Case Study" href="R_case_study_word_cloud.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/actuaries-logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Actuaries' Analytical Cookbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="about_py.html">
   About Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_by_example.html">
   An Introductory Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="learn_more.html">
   Learn More
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Useful_Python_packages.html">
   Useful Python packages for Data Science
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to R
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="about_R.html">
   About R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started_R.html">
   Setting Up R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="introductory_R.html">
   Introduction to R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intermediate_R.html">
   Next Steps With R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="top_ten_r_packages.html">
   Useful Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_DataTable.html">
   R: data.table for actuaries
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Workflow Management
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="version_control.html">
   Version control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="predict_API_gradio.html">
   Py: Productionising predictive models as API
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Regression, Classification and Technical Price
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M05_CS1.html">
   Py: Customer Churn Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multitasking_risk_pricing.html">
   Py/R: Multitasking Risk Pricing Using Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="py_shap_values.html">
   Py: Explainable Models with SHAP
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Life Insurance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="LifeRecipeBook.html">
   R: Life Modelling Recipes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="life_stats.html">
   R: Life Industry Stats in Tableau and R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bayesian-applications.html">
   R: Bayesian Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="trees.html">
   R: Decision Tree Applications
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  General Insurance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="SQL%20Query%20for%20Triangles.html">
   SQL: Queries to Create Triangles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_GLMs.html">
   R: Reserving with GLMs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_Lasso.html">
   R: Reserving with LASSO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_mlr3.html">
   R: Machine Learning Triangles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_Py_triangles_example.html">
   Py: Machine Learning Triangles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_Baudry_Notebook_1_SimulateData_v1.html">
   R: Baudry ML Reserving Pt 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_Baudry_Notebook_2_CreateReservingDatabase_v1.html">
   R: Baudry ML Reserving Pt 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLRWP_R_Baudry_Notebook_3_ApplyMachineLearningReserving_v1.html">
   R: Baudry ML Reserving Pt 3
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Unsupervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M06_CS1.html">
   Py: Socio-Economic Index Construction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M06_CS2.html">
   Py: Clustering Credit Card Fraud
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M06_Ex4.html">
   Py: K-means clustering of COVID dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M06_Ex5.html">
   Py: Hierarchical clustering on COVID dataset
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="R_case_study_word_cloud.html">
   R: Word Cloud Case Study
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Py: Text Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M05_Ex10.html">
   Py: Decision Tree Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M05_Ex18.html">
   Py: Neural Net Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M07_CS1.html">
   Py: Classifying review sentiment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M07_CS2.html">
   Py: Customer Sentiment Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Business Optimization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_2021_S2_Tutorial10_exercise_scipy.html">
   Py: Linear Programming
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Image Recognition
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DAA_M05_CS2.html">
   Py: Image Recognition
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Ethics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="automated_decision.html">
   Automated Decision-Making Systems
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="zbibliography.html">
   Bibliography
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="contributing.html">
   Contributing
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ActuariesInstitute/cookbook/main?urlpath=tree/cookbook/docs/textClassificationEntry.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ActuariesInstitute/cookbook/blob/main/cookbook/docs/textClassificationEntry.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ActuariesInstitute/cookbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ActuariesInstitute/cookbook/edit/main/cookbook/docs/textClassificationEntry.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/textClassificationEntry.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools-and-packages">
   Tools and Packages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-the-code-from-your-browser">
   Run the code from your browser
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-and-cleaning-data">
   Importing and Cleaning Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-extraction">
   Feature Extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words-bow-model">
     Bag of Words (BOW) Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression-classifier">
   Logistic Regression Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#afterward">
   Afterward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-analysis">
   Further Analysis
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Py: Text Classification</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tools-and-packages">
   Tools and Packages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-the-code-from-your-browser">
   Run the code from your browser
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importing-and-cleaning-data">
   Importing and Cleaning Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-extraction">
   Feature Extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words-bow-model">
     Bag of Words (BOW) Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression-classifier">
   Logistic Regression Classifier
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#afterward">
   Afterward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-analysis">
   Further Analysis
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="py-text-classification">
<h1>Py: Text Classification<a class="headerlink" href="#py-text-classification" title="Permalink to this headline">#</a></h1>
<p>By Jonathan Tan. Originally published in Actuaries Digital as <a class="reference external" href="https://www.actuaries.digital/2018/11/20/analytics-snippet-natural-language-processing-text-classification/">Analytics Snippet: Natural Language Processing Text Classification</a>.</p>
<p>According to an article written by <a class="reference external" href="https://www.ibm.com/blogs/watson/2016/05/biggest-data-challenges-might-not-even-know/">IBM</a>, it is estimated at 80% of all data is unstructured. Unstructured data is the messy stuff every quantitative analyst tries to traditionally stay away from. It can include images of accidents, text notes of loss adjusters, social media comments, claim documents and review of medical doctors etc. How can actuaries make use of these kinds of data to add value to the insurer and what techniques are available for handling these types of data? <br><br>
In the insurance industry, text data appears everywhere but is generally more prevalent in the marketing, sales and claims. Listed below are some of the possible areas in which an insurer can benefit from text data analytics: <br><br></p>
<ul class="simple">
<li><p><strong>General Insurance</strong></p></li>
<li><p>Sentiment analysis from customer feedback</p></li>
<li><p>Chatbots for product recommendations and customer service</p></li>
<li><p>Automation of claims management process</p></li>
<li><p><strong>Life Insurance</strong></p></li>
<li><p>Increase accuracy of underwriting process with the use of context analysis from social media platforms</p></li>
<li><p>Improved customer service through timely responses on coverage, billing ect. especially with the massive library of PDSes</p></li>
<li><p><strong>Investments</strong></p></li>
<li><p>Recommendation systems based on risk appetite identification from client conversations</p></li>
</ul>
<br>
In this article, we are going to be looking at one of the topics within Natural Language Processing: Text Classification. The way we are going to handle this problem can be split into 3 distinct parts: <br>
1. Importing and cleaning the dataset <br>
2. Transforming text to numerical features <br>
3. Classifying the complaints using supervised learning techniques<section id="tools-and-packages">
<h2>Tools and Packages<a class="headerlink" href="#tools-and-packages" title="Permalink to this headline">#</a></h2>
<p>The article uses <a class="reference external" href="https://www.python.org/">Python3</a> and the main packages that we will be using are listed below:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pandas.pydata.org/">Pandas</a> and <a class="reference external" href="http://www.numpy.org/">Numpy</a> for general data manipulation</p></li>
<li><p><a class="reference external" href="https://matplotlib.org/">Matplotlib</a> and <a class="reference external" href="https://seaborn.pydata.org/">Seaborn</a> for general data visualisation</p></li>
<li><p><a class="reference external" href="http://scikit-learn.org/stable/">Sci-kit</a> learn packages for both feature extraction and classification model</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import pandas as pd
import numpy as np
import warnings
import pyarrow.parquet as pq
from collections import defaultdict

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-the-code-from-your-browser">
<h2>Run the code from your browser<a class="headerlink" href="#run-the-code-from-your-browser" title="Permalink to this headline">#</a></h2>
<p>The python code in this snippet can be run from your browser through this <a class="reference external" href="https://mybinder.org/v2/gh/jtsw1990/articles.git/master?filepath=textClassificationEntry.ipynb">link</a>. <br><br>
As with the other articles, loading time is to be expected. However, the binder does not require the reader to download the dataset, or any other dependencies to run the models. Furthermore, the reader is encouraged to play around with the code and use a different classification model to get more accurate results than the one presented here!</p>
</section>
<section id="importing-and-cleaning-data">
<h2>Importing and Cleaning Data<a class="headerlink" href="#importing-and-cleaning-data" title="Permalink to this headline">#</a></h2>
<p>The dataset we are using here consists of information regarding finance related complaints that a company has received from its customers.
It is provided by an open source data library managed by the U.S. General Services Administration and can be downloaded <a class="reference external" href="https://catalog.data.gov/dataset/consumer-complaint-database">here</a>.
<br><br>
Since we are trying to predict the category of products based on the complaints received, we can ignore the rest of the columns for the purposes of this exercise and only focus at 2 of them, in particular:</p>
<ul class="simple">
<li><p>Description - Narrative of customer’s complaint</p></li>
<li><p>Product - The category of financial products which the complaint relates to
<br><br></p></li>
</ul>
<p>We will also get rid of null entries as they will not be of any use to us.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>url = &#39;https://www.dropbox.com/s/9whncsovtccbgx8/Consumer_complaints.parquet?dl=1&#39;
df = pd.read_parquet(url)
df = df.loc[(df[&#39;Consumer complaint narrative&#39;].notnull()), [&#39;Consumer complaint narrative&#39;, &#39;Product&#39;]] \
       .reset_index() \
       .drop(&#39;index&#39;, axis = 1)
df = df[(np.logical_not(df.Product.str.contains(&#39;,&#39;))) &amp; (df.Product != &#39;Credit card or prepaid card&#39;)]
df.columns = [&#39;description&#39;, &#39;target&#39;]
pd.set_option(&#39;display.max_colwidth&#39;, 250)
df.head()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>description</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I have outdated information on my credit report that I have previously disputed that has yet to be removed this information is more then seven years old and does not meet credit reporting requirements</td>
      <td>Credit reporting</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I purchased a new car on XXXX XXXX. The car dealer called Citizens Bank to get a 10 day payoff on my loan, good till XXXX XXXX. The dealer sent the check the next day. When I balanced my checkbook on XXXX XXXX. I noticed that Citizens bank had ta...</td>
      <td>Consumer Loan</td>
    </tr>
    <tr>
      <th>2</th>
      <td>An account on my credit report has a mistaken date. I mailed in a debt validation letter to allow XXXX to correct the information. I received a letter in the mail, stating that Experian received my correspondence and found it to be " suspicious '...</td>
      <td>Credit reporting</td>
    </tr>
    <tr>
      <th>3</th>
      <td>This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.</td>
      <td>Debt collection</td>
    </tr>
    <tr>
      <th>4</th>
      <td>This complaint is in regards to Square Two Financial. Refer to CFPB case number XXXX regarding CACH, L. L. C. Square Two Financial has utilized my entire social security number to include date of birth on the pfd document listed with this complai...</td>
      <td>Debt collection</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Next, we will assign each target variable an integer value instead of using the string representation (Credit reporting for example). This allows our models to be able to recognize the responses. We can do this using a variety of methods, but here we will be using sklearn’s LabelEncoder function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>encoder = LabelEncoder()
encoder.fit(df.target)
df = df.assign(encoded_response = lambda x: encoder.transform(x.target))
df[[&#39;target&#39;, &#39;encoded_response&#39;]].drop_duplicates() \
                                  .set_index(&#39;target&#39;) \
                                  .sort_values(&#39;encoded_response&#39;, ascending = True)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>encoded_response</th>
    </tr>
    <tr>
      <th>target</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bank account or service</th>
      <td>0</td>
    </tr>
    <tr>
      <th>Checking or savings account</th>
      <td>1</td>
    </tr>
    <tr>
      <th>Consumer Loan</th>
      <td>2</td>
    </tr>
    <tr>
      <th>Credit card</th>
      <td>3</td>
    </tr>
    <tr>
      <th>Credit reporting</th>
      <td>4</td>
    </tr>
    <tr>
      <th>Debt collection</th>
      <td>5</td>
    </tr>
    <tr>
      <th>Money transfers</th>
      <td>6</td>
    </tr>
    <tr>
      <th>Mortgage</th>
      <td>7</td>
    </tr>
    <tr>
      <th>Other financial service</th>
      <td>8</td>
    </tr>
    <tr>
      <th>Payday loan</th>
      <td>9</td>
    </tr>
    <tr>
      <th>Prepaid card</th>
      <td>10</td>
    </tr>
    <tr>
      <th>Student loan</th>
      <td>11</td>
    </tr>
    <tr>
      <th>Vehicle loan or lease</th>
      <td>12</td>
    </tr>
    <tr>
      <th>Virtual currency</th>
      <td>13</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see from the output above, that our resulting dataset contains 14 unique categories which we will try to classify complaints into by training our model to “understand” the narrative. <br><br>
After encoding our target variable, we can then move on to splitting our dataset for training and validation purposes. Train test splits are a crucial part of any modelling process and prevents <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>. Here, we are using an 80/20 split and setting a random seed for reproducibility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x_train, x_test, y_train, y_test, indices_train, indices_test = train_test_split(df.description, 
                                                                                 df.encoded_response,
                                                                                 df.index,
                                                                                 test_size = 0.2, 
                                                                                 random_state = 1)
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-extraction">
<h2>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this headline">#</a></h2>
<p>Just as we have encoded our target variables, we must also find a way to transform our description data out if its string representation into a numerical one. However, unlike the target variables, this process is not as simple as allocating an integer value to each unique complaint. Keep in mind that a meaningful transformation must somehow display some form of homogeneity between complaints within the same product categories.</p>
<section id="bag-of-words-bow-model">
<h3>Bag of Words (BOW) Model<a class="headerlink" href="#bag-of-words-bow-model" title="Permalink to this headline">#</a></h3>
<p>One way of transforming a document full of text data into numerical features is by using the BOW (Bag of Words) model. Put simply, all it does is assign each unique word (or token) an ID number and counts up its frequency. For example, if we have a document: <br><br>
<code class="docutils literal notranslate"><span class="pre">&quot;This</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">cat.</span> <span class="pre">That</span> <span class="pre">is</span> <span class="pre">a</span> <span class="pre">dog&quot;</span></code>
<br><br>
The BOW representation would simply be: <br><br>
<code class="docutils literal notranslate"><span class="pre">BOW</span> <span class="pre">=</span> <span class="pre">{&quot;This&quot;:</span> <span class="pre">1,</span> <span class="pre">&quot;is&quot;:</span> <span class="pre">2,</span> <span class="pre">&quot;a&quot;:</span> <span class="pre">2,</span> <span class="pre">&quot;cat&quot;</span> <span class="pre">:</span> <span class="pre">1,</span> <span class="pre">&quot;That&quot;</span> <span class="pre">:</span> <span class="pre">1,</span> <span class="pre">&quot;dog&quot;</span> <span class="pre">:</span> <span class="pre">1}</span></code>
<br><br>
Notice that the document shown above is clearly about a cat and a dog. However, our BOW model shows that the most frequent words present in the document are “is” and “a”. These common words are also known as <a class="reference external" href="https://en.wikipedia.org/wiki/Stop_words">“stop words”</a> and are usually filtered out of the BOW model during the pre-processing phase to prevent overpowering the words that have actual importance. There are many different little tricks and techniques for choosing the most suitable bag of words to represent your documents and most can be implemented simply through a line (or two) of code using <a class="reference external" href="https://docs.python.org/2/library/re.html">regular expressions</a>, which is a great way to filter texts and I highly recommend getting comfortable with using them.<br><br>
How does this link back to the goal of having numerical features as our inputs? Imagine having a thousand text documents and extracting all (a subset) of the unique tokens that we think best represents them. Now, we can assign each unique token to a column in a dataframe and populate the rows with each document’s count of the respective words. Following the example above, our single document would produce a dataframe that looks like: <br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pd.DataFrame({&quot;This&quot;: 1, &quot;is&quot;: 2, &quot;a&quot;: 2, &quot;cat&quot; : 1,
              &quot;That&quot; : 1, &quot;dog&quot; : 1}, index = range(1))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>This</th>
      <th>is</th>
      <th>a</th>
      <th>cat</th>
      <th>That</th>
      <th>dog</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Realistically, if we had chosen 15,000 unique tokens from the 1000 documents, our input matrix would then have 15,000 columns! You can start to imagine how sparse (full of zeros) our resulting input matrix will be! This technique is also commonly known as count vectorizing. <br><br>
In this article however, we will be using a more robust model compared to count vectorizing called (TF-IDF) Term Frequency - Inverse Document Frequency, and it is defined as:</p>
<p><span class="math notranslate nohighlight">\(w_{i,j} = tf_{i,j} * log(\dfrac{N}{df_i})\)</span>
<br><br>
<span class="math notranslate nohighlight">\(w_{i,j}\)</span> = Weight for word(i) in document(j) <br>
<span class="math notranslate nohighlight">\(tf_{i,j}\)</span> = Count of word(i) in document(j) <br>
<span class="math notranslate nohighlight">\(N\)</span> = Total number of documents <br>
<span class="math notranslate nohighlight">\(df_i\)</span> = How many documents word(i) appears in<br><br></p>
<p>We can see that, the first term of the TF-IDF model is just the count of the word in the document as before. The magic happens in the second term where the model imposes an additional condition for a word to be deemed “important”. Just as an example, if the word “bank” appears in every single document, it wouldn’t be of much use in differentiating the documents, and the second term of the TF-IDF model expresses this by reducing the whole weight down to 0. For a more detailed explanation on how TF-IDF works, there is an article written at <a class="reference external" href="https://www.elephate.com/blog/what-is-tf-idf/">elephate.com</a> explaining it quite elegantly.</p>
<p>There are a variety of packages that help to automate the vectorizing process, but we have chosen to use the Sci-kit learn API due to its easy of usage and interpretability. Here, we instantiate a TfidfVectorizer model, with a few note-worthy details: <br></p>
<ul class="simple">
<li><p>Sublinear_tf uses a logarithmic form of frequency as 20 occurrences of a word does not imply 20 times the importance in most cases <br></p></li>
<li><p>The model will ignore words that appear in less than 5 documents, as well as more than 70% of the total documents <br></p></li>
<li><p>Normalization is set to L2 (Not to be confused with L2 regularisation) so that all vectors are scaled to have a magnitude of 1 (The equivalent of standardizing your features) <br></p></li>
<li><p>There is a layer of pre-processing to remove numerical characters and symbols within the documents using a regular expression (REGEX)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tfidf_vectorizer = TfidfVectorizer(sublinear_tf = True, 
                                   stop_words = &#39;english&#39;,
                                   min_df = 5,
                                   max_df = 0.7,
                                   norm = &#39;l2&#39;,
                                   token_pattern = r&#39;\b[^_\d\W]+\b&#39;)
</pre></div>
</div>
</div>
</div>
<p>We then use the model to fit our original description data, and convert all that sweet text information into something numerical!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tfidf_train = tfidf_vectorizer.fit_transform(x_train.values)
tfidf_test = tfidf_vectorizer.transform(x_test.values)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(len(tfidf_vectorizer.get_feature_names()))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19285
</pre></div>
</div>
</div>
</div>
<p>We can see that our resulting dictionary consists of 19,285 different unique words!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tfidf_df = pd.SparseDataFrame(tfidf_train, 
                              columns = tfidf_vectorizer.get_feature_names(),
                              copy = False)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pd.options.display.max_columns = 10
tfidf_df.head()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aa</th>
      <th>aaa</th>
      <th>aaddress</th>
      <th>aadvantage</th>
      <th>aafes</th>
      <th>...</th>
      <th>zone</th>
      <th>zoned</th>
      <th>zones</th>
      <th>zoning</th>
      <th>zwicker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 19285 columns</p>
</div></div></div>
</div>
<p>As mentioned above, the 19,285 words chosen to be in our “dictionary” become the columns of our input matrix and just to reiterate, since we have so many columns and each row only consists of words within 1 document, the resulting matrix will be extremely sparse! (Consisting mostly of zeros) <br><br>
Now that we have extracted some numerical features from our dataset, it is time to use them to train a classifier!</p>
</section>
</section>
<section id="logistic-regression-classifier">
<h2>Logistic Regression Classifier<a class="headerlink" href="#logistic-regression-classifier" title="Permalink to this headline">#</a></h2>
<p>In this example, we have chosen to use a basic <a class="reference external" href="http://www.appstate.edu/~whiteheadjc/service/logit/intro.htm">logistic regression model</a> to classify the documents due to tractability and convention. However, more complex models such as neural networks, decision trees, naive bayesian classifiers or other relevant models can also be used to do the following classification and the reader is encouraged to try different machine learning models to see which ones give the most accurate results! <br><br>
Firstly, we instantiate a logistic regression classifier from the sklearn package and proceed to fit our TF-IDF vectorized matrix and our encoded training labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lr_classifier = LogisticRegression()
lr_classifier.fit(tfidf_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</div>
</div>
</div>
<p>We can observe that amongst the model parameters, sklearn has automatically set ‘penalty’ to L2. This is a form of regularization, which weighs the benefits of a better fit against using more features by adding an extra term to the objective function. Coursera does quite a good job in explaining what L2 regularization in logisitic regression means <a class="reference external" href="https://www.coursera.org/lecture/ml-classification/l2-regularized-logistic-regression-DBTNt">here</a>. Recall that when using the BOW model, we ended up creating thousands of features. Adding regularization to our model would then help to prevent creating too many of them!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>coefficients = pd.DataFrame(dict(zip(tfidf_df.columns,lr_classifier.coef_[0])),index = [0]).T.reset_index()
coefficients.columns = [&#39;features&#39;, &#39;coefficients&#39;]
coefficients.head(10)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>coefficients</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aa</td>
      <td>-0.064147</td>
    </tr>
    <tr>
      <th>1</th>
      <td>aaa</td>
      <td>-0.422178</td>
    </tr>
    <tr>
      <th>2</th>
      <td>aaddress</td>
      <td>-0.019091</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aadvantage</td>
      <td>0.808569</td>
    </tr>
    <tr>
      <th>4</th>
      <td>aafes</td>
      <td>-0.143279</td>
    </tr>
    <tr>
      <th>5</th>
      <td>aag</td>
      <td>-0.051489</td>
    </tr>
    <tr>
      <th>6</th>
      <td>aand</td>
      <td>-0.063603</td>
    </tr>
    <tr>
      <th>7</th>
      <td>aargon</td>
      <td>-0.150654</td>
    </tr>
    <tr>
      <th>8</th>
      <td>aarp</td>
      <td>-0.069611</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ab</td>
      <td>-0.261654</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Since we have converted all our “text” data into numerical features, we can view the weights and features just as we would be able to for any other logisitic regression model on numerical data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pred = lr_classifier.predict(tfidf_test)
score = metrics.accuracy_score(y_test, pred)
print(score)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8517154487303741
</pre></div>
</div>
</div>
</div>
<p>After running the model on the validation set, we can see that we attained some pretty decent results with an overall accuracy of 85.2% with just a simple logistic regression classifier. We can drill down into this result by evaluating the <a class="reference external" href="https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology">confusion matrix</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cm = metrics.confusion_matrix(y_test, pred)
cm = cm.astype(&#39;float&#39;) / cm.sum(axis = 1)[:, np.newaxis]
</pre></div>
</div>
</div>
</div>
<p>Due to the huge imbalance of data points between the different categories, the resulting figures in the confusion matrix are normalized to produce clearer distinctions between “good” and “poor” performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize = (15,15))
sns.heatmap(cm, 
            annot = True, 
            fmt = &quot;.3f&quot;, 
            linewidths = 0.5, 
            square = True, 
            cmap = &#39;Reds&#39;, 
            xticklabels = encoder.classes_,
            yticklabels = encoder.classes_)
plt.ylabel(&#39;Actual&#39;)
plt.xlabel(&#39;Predicted&#39;)
all_sample_title = &#39;Accuracy Score: {}&#39;.format(score)
plt.title(all_sample_title, size = 15)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5,1,&#39;Accuracy Score: 0.8517154487303741&#39;)
</pre></div>
</div>
<img alt="../_images/textClassificationEntry_39_1.png" src="../_images/textClassificationEntry_39_1.png" />
</div>
</div>
<p>One of the more obvious results we can observe just from diagonals of the matrix is that “Other financial service”, “Vehicle loan or lease” and “Virtual currency” categories had no correct predictions. We must note however, that the number of data points we had for each of these categories were insignificant compared to the others and the model probably treated those instances as errors instead of a distinct category. This bias however, can be corrected by techniques such as <a class="reference external" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis">over and undersampling</a>. Let’s investigate further to see if the model does indeed treat the documents within these categories as errors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def report2dict(cr):
    &#39;&#39;&#39;Function solely for formatting purposes, can be ignored&#39;&#39;&#39;
    
    tmp = list()
    for row in cr.split(&quot;\n&quot;):
        parsed_row = [x for x in row.split(&quot;  &quot;) if len(x) &gt; 0]
        if len(parsed_row) &gt; 0:
            tmp.append(parsed_row)
    measures = tmp[0]
    D_class_data = defaultdict(dict)
    for row in tmp[1:]:
        class_label = row[0]
        for j, m in enumerate(measures):
            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())
    return D_class_data
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>results = metrics.classification_report(y_test, pred,
                                     target_names = encoder.classes_)
pd.DataFrame(report2dict(results)).transpose()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\users\jtan\appdata\local\continuum\anaconda3\lib\site-packages\sklearn\metrics\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  &#39;precision&#39;, &#39;predicted&#39;, average, warn_for)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>f1-score</th>
      <th>precision</th>
      <th>recall</th>
      <th>support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bank account or service</th>
      <td>0.78</td>
      <td>0.76</td>
      <td>0.81</td>
      <td>2965.0</td>
    </tr>
    <tr>
      <th>Checking or savings account</th>
      <td>0.22</td>
      <td>0.98</td>
      <td>0.12</td>
      <td>424.0</td>
    </tr>
    <tr>
      <th>Consumer Loan</th>
      <td>0.67</td>
      <td>0.73</td>
      <td>0.63</td>
      <td>1884.0</td>
    </tr>
    <tr>
      <th>Credit card</th>
      <td>0.81</td>
      <td>0.80</td>
      <td>0.83</td>
      <td>3696.0</td>
    </tr>
    <tr>
      <th>Credit reporting</th>
      <td>0.87</td>
      <td>0.88</td>
      <td>0.86</td>
      <td>6240.0</td>
    </tr>
    <tr>
      <th>Debt collection</th>
      <td>0.87</td>
      <td>0.84</td>
      <td>0.90</td>
      <td>9600.0</td>
    </tr>
    <tr>
      <th>Money transfers</th>
      <td>0.68</td>
      <td>0.76</td>
      <td>0.61</td>
      <td>301.0</td>
    </tr>
    <tr>
      <th>Mortgage</th>
      <td>0.94</td>
      <td>0.92</td>
      <td>0.96</td>
      <td>7359.0</td>
    </tr>
    <tr>
      <th>Other financial service</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>Payday loan</th>
      <td>0.49</td>
      <td>0.71</td>
      <td>0.37</td>
      <td>342.0</td>
    </tr>
    <tr>
      <th>Prepaid card</th>
      <td>0.68</td>
      <td>0.81</td>
      <td>0.59</td>
      <td>283.0</td>
    </tr>
    <tr>
      <th>Student loan</th>
      <td>0.91</td>
      <td>0.91</td>
      <td>0.90</td>
      <td>2765.0</td>
    </tr>
    <tr>
      <th>Vehicle loan or lease</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>186.0</td>
    </tr>
    <tr>
      <th>Virtual currency</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>avg / total</th>
      <td>0.84</td>
      <td>0.85</td>
      <td>0.85</td>
      <td>36113.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that calling the classification_report function actually produces a <em>UndefinedMetricWarning</em> but what does this mean? <br><br>
If we look deeper into this, the error tells us that the model, made no predictions (correctly or incorrectly) for those 3 categories, which supports the hypothesis we made earlier that these documents were just treated as errors! Since we now roughly know the reasons for misclassifications in these 3 categories, let’s try to look at a category where data points were not sparse and try to find an explanation for those misclassified documents. <br><br>
Shown below are some examples where ‘Checking and savings account’ narratives were wrongly classified as ‘Bank account and service’.</p>
<p>Categories with more data points generally had a better score, and the reasons for misclassifications in these categories seem to follow the trend of overlapping categories. (For example, 320 descriptions that were supposed to be “Checking and savings account” related were wrongly classified as “Bank account and service”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def observe_errors(actual_response, wrongly_predicted_response):
    warnings.filterwarnings(action = &#39;ignore&#39;, category = DeprecationWarning)
    compare = pd.DataFrame(list(zip(x_test, y_test, pred)), columns = [&#39;description&#39;, &#39;actual&#39;, &#39;predicted&#39;])
    compare = compare.assign(actual_product = encoder.inverse_transform(compare.actual),
                             predicted_product = encoder.inverse_transform(compare.predicted)) \
                     .loc[(compare.actual == actual_response) &amp; (compare.predicted == wrongly_predicted_response),
                         [&#39;description&#39;, &#39;actual_product&#39;, &#39;predicted_product&#39;]]
    return compare
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>observe_errors(actual_response = 1, wrongly_predicted_response = 0).tail(5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>description</th>
      <th>actual_product</th>
      <th>predicted_product</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35632</th>
      <td>On Saturday morning around   XXXX   XXXX  , I went to the Chase Bank #  XXXX  on  XXXX   XXXX   XXXX   XXXX  in  XXXX , Texas to try to open an savings account. I was received by the Teller I asked her nicely that I wanted to open an savings acco...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35748</th>
      <td>PNC bank changed the terms on my bank account a second time without notifying me. The first change would prevent me from ever having a transaction in the bank with a human being without being charged a fee. I learned about this issue after findin...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35835</th>
      <td>On  XXXX   XXXX ,  2017 , I deposited several checks into my checking account, one of which was in excess of {$5000.00}. The branch manager put a hold on this check thereby making these funds unavailable to me for the purpose to which they were i...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>35870</th>
      <td>I did a complaint to Bank of America, because  XXXX  charge withdraw money from my account, one year ago my daughter call  XXXX  for do a question, but we decided do not use  XXXX  because a Mistake the company withdraw money from my bank account...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
    <tr>
      <th>36085</th>
      <td>I opened a PMA checking and brokerage account with  Wells Fargo  in  XXXX .   I had  XXXX  checking account, a credit card and ATM card at that time.     At some point in  XXXX , inexplicably, a second checking account appeared on my statements. ...</td>
      <td>Checking or savings account</td>
      <td>Bank account or service</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that the misclassified complaints shown above is quite ambiguous and contain ideas and keywords within the narrative related to both categories, which is presumably why the model would have misclassified them.</p>
<p>Because of the how text data is converted into numerical features, data pre-processing is an extremely important step when it comes to NLP problems and the “garbage-in, garbage-out” property can be very prevalent compared to other machine learning techniques. Also note that, in this problem that there are existing labels in the dataset, and we could have just as easily used any other supervised learning techniques to classify the documents. If, however, no labels are available, we would then have to turn towards unsupervised learning algorithms such as SVM, K-means or LDA to try and cluster the documents into sensible categories.</p>
</section>
<section id="afterward">
<h2>Afterward<a class="headerlink" href="#afterward" title="Permalink to this headline">#</a></h2>
<p>We have essentially just taught the computer how to “understand” a small selected group of documents in a very human way with approximately 50 lines of code (ignoring the functions for visualisation)! Regardless of whether you are working in (or plan to work in) the general insurance, life insurance, health insurance or investments sector, text data is a big part of the business, and with the ever-growing focus on customer satisfaction, the need for actuaries to learn how to deal with this data type will be an integral part of dealing with uncertainty. <br><br>
For more resources on Natural Language Processing techniques, I highly recommend <a class="reference external" href="http://blog.aylien.com/12-of-the-best-free-natural-language-processing-and-machine-learning-educational-resources/">AYLIEN</a>, which is a data science blog that provides quite a comprehensive list of learning material from journal articles, lectures and videos for both beginners and advanced practitioners.</p>
<p>If you are interested in other machine learning models and its applications in the insurance industry, you can check out Jacky’s previous Analytics Snippet “Multitasking Risk Pricing Using Deep Learning” <a class="reference external" href="https://www.actuaries.digital/2018/08/23/analytics-snippet-multitasking-risk-pricing-using-deep-learning/">here</a>.</p>
</section>
<section id="further-analysis">
<h2>Further Analysis<a class="headerlink" href="#further-analysis" title="Permalink to this headline">#</a></h2>
<p>If you would like to further explore the capabilities of different BOW and classification models using this dataset, <a class="reference external" href="https://www.kaggle.com/sebastienverpile/consumercomplaintsdata/home">Kaggle</a> provides an outlet to publish your results and discuss them with others!</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ActuariesInstitute/cookbook",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="R_case_study_word_cloud.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">R: Word Cloud Case Study</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="DAA_M05_Ex10.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Py: Decision Tree Classification</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By YDAWG, DAPC, YAC and other contributors.<br/>
  
    <div class="extra_footer">
       The Actuaries' Analytical Cookbook is a series of data and analytics recipes to help actuaries quickly get started with a new project.   This site is intended to be a resource to actuaries in both data science and traditional fields.  Opinions expressed in this publication are the opinions of contributors and do not necessarily represent those of either the Institute of Actuaries of Australia (the ‘Institute’), its members, directors, officers, employees, agents, or that of the employers of the contributors. <br>© Institute of Actuaries of Australia and Contributors 2021. All rights reserved.
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>